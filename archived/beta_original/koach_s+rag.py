import os
import subprocess
import whisper
from openai import OpenAI
import shutil
from pydub import AudioSegment
import textgrid
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import numpy as np
import json
from sentence_transformers import SentenceTransformer
import faiss
import torch

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("Koach")


class KnowledgeBase:
    """í•œêµ­ì–´ ë°œìŒ ì§€ì‹ ë² ì´ìŠ¤"""

    def __init__(
        self,
        knowledge_dir: str = "knowledge",
        embedding_model: str = "paraphrase-multilingual-MiniLM-L12-v2",
    ):
        """
        Args:
            knowledge_dir: ì§€ì‹ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
            embedding_model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        self.knowledge_dir = knowledge_dir
        os.makedirs(knowledge_dir, exist_ok=True)

        # ë¬¸ì„œ ì €ì¥ì†Œ
        self.documents = []
        self.document_ids = []

        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer(embedding_model)

        # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.index = None

        # ê¸°ë³¸ ì§€ì‹ ë¡œë“œ
        self.load_knowledge()

    def load_knowledge(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ë¬¸ì„œ ë¡œë“œ"""
        logger.info("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì¤‘...")

        # ì§€ì‹ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ
        file_paths = list(Path(self.knowledge_dir).glob("*.json"))

        if not file_paths:
            logger.warning("ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€ì‹ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            self.create_default_knowledge()
            file_paths = list(Path(self.knowledge_dir).glob("*.json"))

        # ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
        documents = []
        document_ids = []

        for file_path in file_paths:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                for item in data:
                    if "content" in item and "id" in item:
                        documents.append(item["content"])
                        document_ids.append(item["id"])
            except Exception as e:
                logger.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")

        # ë¬¸ì„œ ì €ì¥
        self.documents = documents
        self.document_ids = document_ids

        # ì„ë² ë”© ìƒì„± ë° ì¸ë±ìŠ¤ êµ¬ì¶•
        self.build_index()

        logger.info(f"âœ… {len(self.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

    def create_default_knowledge(self):
        """ê¸°ë³¸ ì§€ì‹ ìƒì„±"""
        logger.info("ê¸°ë³¸ í•œêµ­ì–´ ë°œìŒ ì§€ì‹ ìƒì„± ì¤‘...")

        # í•œêµ­ì–´ ë°œìŒ ê¸°ë³¸ ì§€ì‹
        basic_knowledge = [
            {
                "id": "consonants_basic",
                "content": "í•œêµ­ì–´ ììŒ(ì´ˆì„±): ã„±(g/k), ã„´(n), ã„·(d/t), ã„¹(r/l), ã…(m), ã…‚(b/p), ã……(s), ã…‡(silent/ng), ã…ˆ(j), ã…Š(ch), ã…‹(k), ã…Œ(t), ã…(p), ã…(h). ê° ììŒì€ ìœ„ì¹˜ì™€ ë°œì„± ë°©ë²•ì— ë”°ë¼ êµ¬ë¶„ëœë‹¤.",
            },
            {
                "id": "vowels_basic",
                "content": "í•œêµ­ì–´ ëª¨ìŒ: ã…(a), ã…“(eo), ã…—(o), ã…œ(u), ã…¡(eu), ã…£(i), ã…(ae), ã…”(e), ã…š(oe), ã…Ÿ(wi). ì… ëª¨ì–‘ê³¼ í˜€ì˜ ìœ„ì¹˜ê°€ ë°œìŒì— ì¤‘ìš”í•˜ë‹¤.",
            },
            {
                "id": "final_consonants",
                "content": "í•œêµ­ì–´ ë°›ì¹¨(ì¢…ì„±): ë°›ì¹¨ì€ ë‹¨ì–´ ëì— ì˜¤ëŠ” ììŒìœ¼ë¡œ, ë°œìŒì´ ì•½í™”ë˜ê±°ë‚˜ ë³€í˜•ë  ìˆ˜ ìˆë‹¤. ì£¼ìš” ë°›ì¹¨ ë°œìŒ: ã„±, ã„´, ã„·, ã„¹, ã…, ã…‚, ã…‡. íŠ¹íˆ ã„±, ã„·, ã…‚ì€ ë‹¨ì–´ ëì—ì„œ ë¶ˆíŒŒìŒìœ¼ë¡œ ë°œìŒí•œë‹¤.",
            },
            {
                "id": "pronunciation_rules",
                "content": "í•œêµ­ì–´ ë°œìŒ ê·œì¹™: 1) ì—°ìŒ í˜„ìƒ: ë°›ì¹¨ì´ ë‹¤ìŒ ìŒì ˆì˜ ì²« ì†Œë¦¬ë¡œ ë„˜ì–´ê°€ëŠ” í˜„ìƒ 2) ììŒ ë™í™”: ì¸ì ‘í•œ ììŒë¼ë¦¬ ì„œë¡œ ì˜í–¥ì„ ì£¼ì–´ ë¹„ìŠ·í•œ ì†Œë¦¬ë¡œ ë³€í•˜ëŠ” í˜„ìƒ 3) êµ¬ê°œìŒí™”: ã„·, ã…Œì´ ã…£ ëª¨ìŒ ì•ì—ì„œ ã…ˆ, ã…Šìœ¼ë¡œ ë³€í•˜ëŠ” í˜„ìƒ 4) ê²½ìŒí™”: íŠ¹ì • í™˜ê²½ì—ì„œ í‰ìŒì´ ê²½ìŒìœ¼ë¡œ ë³€í•˜ëŠ” í˜„ìƒ",
            },
            {
                "id": "common_foreigner_errors",
                "content": "ì™¸êµ­ì¸ í•™ìŠµìë“¤ì˜ í”í•œ ë°œìŒ ì‹¤ìˆ˜: 1) ã…“ì™€ ã…— êµ¬ë³„ ì–´ë ¤ì›€ 2) ã„¹ ë°œìŒ (ì˜ì–´ L/Rê³¼ ë‹¤ë¦„) 3) ë°›ì¹¨ ë°œìŒ ëˆ„ë½ 4) ê²½ìŒ(ã„²,ã„¸,ã…ƒ,ã…†,ã…‰)ê³¼ í‰ìŒ êµ¬ë³„ ì–´ë ¤ì›€ 5) ì¥ë‹¨ìŒ êµ¬ë³„ ë¶€ì¡± 6) ì—°ìŒ ê·œì¹™ ì ìš© ì‹¤íŒ¨",
            },
            {
                "id": "rhythm_intonation",
                "content": "í•œêµ­ì–´ ë¦¬ë“¬ê³¼ ì–µì–‘: í•œêµ­ì–´ëŠ” ìŒì ˆ ë‹¨ìœ„ì˜ ë¦¬ë“¬ì„ ê°€ì§„ë‹¤. ë¬¸ì¥ì˜ ì˜ë¯¸ì— ë”°ë¼ ì–µì–‘ íŒ¨í„´ì´ ë‹¬ë¼ì§„ë‹¤. ì˜ë¬¸ë¬¸ì€ ëì´ ì˜¬ë¼ê°€ê³ , í‰ì„œë¬¸ì€ ë‚´ë ¤ê°„ë‹¤. ê°ì • í‘œí˜„ì— ë”°ë¼ ì–µì–‘ì˜ êµ´ê³¡ì´ ì»¤ì§ˆ ìˆ˜ ìˆë‹¤.",
            },
            {
                "id": "practice_techniques",
                "content": "ë°œìŒ ì—°ìŠµ ê¸°ë²•: 1) ì… ëª¨ì–‘ ê±°ìš¸ë¡œ í™•ì¸í•˜ë©° ì—°ìŠµ 2) ë…¹ìŒí•˜ê³  ì›ì–´ë¯¼ê³¼ ë¹„êµ 3) ëŠë¦¬ê²Œ ë°œìŒí•œ í›„ ì ì°¨ ì†ë„ ë†’ì´ê¸° 4) ìµœì†ŒëŒ€ë¦½ìŒ(ë¹„ìŠ·í•œ ì†Œë¦¬ ë‹¨ì–´) ì—°ìŠµ 5) í˜€ ìœ„ì¹˜ ì˜ì‹í•˜ë©° ë°œìŒí•˜ê¸° 6) ê³¼ì¥ëœ ë°œìŒìœ¼ë¡œ ì‹œì‘í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì ˆ",
            },
            {
                "id": "tense_consonants",
                "content": "ê²½ìŒ(ëœì†Œë¦¬) ë°œìŒ: ã„², ã„¸, ã…ƒ, ã…†, ã…‰ëŠ” ì„±ëŒ€ë¥¼ ê¸´ì¥ì‹œí‚¤ê³  ê°•í•˜ê²Œ ë°œìŒí•œë‹¤. í‰ìŒê³¼ ë¹„êµ: 'ê°€ë‹¤(gada)'ì™€ 'ê¹Œë‹¤(kkada)', 'ë°”ë‹¤(bada)'ì™€ 'ë¹ ë‹¤(ppada)'ì˜ ì°¨ì´ ì¸ì‹í•˜ê¸°.",
            },
            {
                "id": "aspirated_consonants",
                "content": "ê²©ìŒ(ê±°ì„¼ì†Œë¦¬) ë°œìŒ: ã…‹, ã…Œ, ã…, ã…ŠëŠ” ê°•í•œ ê³µê¸°ë¥¼ ë‚´ë³´ë‚´ë©° ë°œìŒí•œë‹¤. 'ì¹´ë©”ë¼(kamera)', 'íƒ€ë‹¤(tada)', 'íŒŒë‹¤(pada)', 'ì°¨ë‹¤(chada)'ì—ì„œ ê±°ì„¼ ì†Œë¦¬ë¥¼ ëŠë‚„ ìˆ˜ ìˆë‹¤.",
            },
            {
                "id": "linking_sounds",
                "content": "ì—°ìŒ í˜„ìƒ: ë°›ì¹¨ì´ ìˆëŠ” ë‹¨ì–´ ë’¤ì— ëª¨ìŒìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¡°ì‚¬ë‚˜ ì–´ë¯¸ê°€ ì˜¤ë©´, ë°›ì¹¨ì€ ë‹¤ìŒ ìŒì ˆì˜ ì´ˆì„±ì²˜ëŸ¼ ë°œìŒëœë‹¤. ì˜ˆ: 'ê½ƒì´(ê¼¬ì¹˜)', 'ë°¥ì„(ë°”ë¸”)', 'ì±…ì€(ì±„ê·¼)'",
            },
        ]

        # ì§€ì‹ ì €ì¥
        with open(
            os.path.join(self.knowledge_dir, "basic_pronunciation.json"),
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(basic_knowledge, f, ensure_ascii=False, indent=2)

        logger.info("âœ… ê¸°ë³¸ ì§€ì‹ ìƒì„± ì™„ë£Œ")

    def build_index(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if not self.documents:
            logger.warning("ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë¬¸ì„œ ì„ë² ë”© ìƒì„±
        embeddings = self.model.encode(self.documents)

        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(np.array(embeddings).astype("float32"))

        logger.info(f"âœ… {len(self.documents)}ê°œ ë¬¸ì„œì— ëŒ€í•œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """ì§ˆì˜ì— ê´€ë ¨ëœ ì§€ì‹ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

        Returns:
            List[Dict]: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.index or not self.documents:
            logger.warning("ê²€ìƒ‰í•  ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ì§ˆì˜ ì„ë² ë”©
        query_embedding = self.model.encode([query])

        # ìœ ì‚¬ë„ ê²€ìƒ‰
        scores, indices = self.index.search(
            np.array(query_embedding).astype("float32"),
            k=min(top_k, len(self.documents)),
        )

        # ê²°ê³¼ ì •ë¦¬
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.documents) and idx >= 0:
                results.append(
                    {
                        "id": self.document_ids[idx],
                        "content": self.documents[idx],
                        "score": float(scores[0][i]),
                    }
                )

        return results

    def add_document(self, doc_id: str, content: str):
        """ìƒˆ ë¬¸ì„œ ì¶”ê°€

        Args:
            doc_id: ë¬¸ì„œ ID
            content: ë¬¸ì„œ ë‚´ìš©
        """
        # ë¬¸ì„œ ì¶”ê°€
        self.documents.append(content)
        self.document_ids.append(doc_id)

        # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        self.build_index()


class Koach:
    """í•œêµ­ì–´ ë°œìŒ í‰ê°€ ë° í”¼ë“œë°± ì‹œìŠ¤í…œ"""

    def __init__(self, config: Optional[Dict] = None):
        """
        Args:
            config: ì„¤ì • íŒŒë¼ë¯¸í„° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        # ê¸°ë³¸ ì„¤ì •
        self.config = {
            # íŒŒì¼ ê²½ë¡œ
            "learner_audio": "input/learner.m4a",
            "native_audio": "input/native.m4a",
            "output_dir": "output",
            "wav_dir": "wav",
            "mfa_input_dir": "mfa_input",
            "mfa_output_dir": "aligned",
            # ëª¨ë¸ ê²½ë¡œ
            "lexicon_path": "models/korean_mfa.dict",
            "acoustic_model": "models/korean_mfa.zip",
            # Whisper ëª¨ë¸ í¬ê¸°
            "whisper_model": "base",
            # OpenAI ëª¨ë¸
            "openai_model": "gpt-4o",
            # RAG ì„¤ì •
            "use_rag": True,
            "knowledge_dir": "knowledge",
            "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
        }

        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if config:
            self.config.update(config)

        # OpenAI API í‚¤ ì„¤ì •
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            logger.warning("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self._setup_paths()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_directories()

        # RAG ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼)
        if self.config["use_rag"]:
            self.knowledge_base = KnowledgeBase(
                knowledge_dir=self.config["knowledge_dir"],
                embedding_model=self.config["embedding_model"],
            )
        else:
            self.knowledge_base = None

    # [ê¸°ì¡´ ë©”ì†Œë“œë“¤ì€ ë™ì¼í•˜ê²Œ ìœ ì§€]

    def _setup_paths(self):
        """íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        # ì…ë ¥ íŒŒì¼
        self.learner_audio = self.config["learner_audio"]
        self.native_audio = self.config["native_audio"]

        # ë””ë ‰í† ë¦¬
        self.wav_dir = self.config["wav_dir"]
        self.mfa_input = self.config["mfa_input_dir"]
        self.mfa_output = self.config["mfa_output_dir"]

        # ë³€í™˜ëœ WAV íŒŒì¼
        self.learner_wav = os.path.join(self.wav_dir, "learner.wav")
        self.native_wav = os.path.join(self.wav_dir, "native.wav")

        # Whisper ì „ì‚¬ ê²°ê³¼
        self.learner_transcript = os.path.join(self.wav_dir, "learner.txt")
        self.native_transcript = os.path.join(self.wav_dir, "native.txt")

        # ì •ë‹µ ìŠ¤í¬ë¦½íŠ¸
        self.script_path = os.path.join(self.wav_dir, "script.txt")

        # MFA ê´€ë ¨ íŒŒì¼
        self.lexicon_path = self.config["lexicon_path"]
        self.acoustic_model = self.config["acoustic_model"]

        # TextGrid íŒŒì¼
        self.learner_textgrid = os.path.join(self.mfa_output, "learner.TextGrid")
        self.native_textgrid = os.path.join(self.mfa_output, "native.TextGrid")

    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.wav_dir, exist_ok=True)
        os.makedirs(self.mfa_input, exist_ok=True)
        os.makedirs(self.mfa_output, exist_ok=True)
        if self.config["use_rag"]:
            os.makedirs(self.config["knowledge_dir"], exist_ok=True)

    def convert_audio(self, input_path: str, output_path: str) -> bool:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            input_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ WAV íŒŒì¼ ê²½ë¡œ

        Returns:
            bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"ğŸ§ ë³€í™˜ ì¤‘: {input_path} â†’ {output_path}")
            audio = AudioSegment.from_file(input_path)
            audio = audio.set_channels(1).set_frame_rate(16000)
            audio.export(output_path, format="wav")
            logger.info("âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, wav_path: str, transcript_path: str) -> Optional[str]:
        """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬

        Args:
            wav_path: WAV íŒŒì¼ ê²½ë¡œ
            transcript_path: ì „ì‚¬ ê²°ê³¼ ì €ì¥ ê²½ë¡œ

        Returns:
            Optional[str]: ì „ì‚¬ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“ Whisper ì „ì‚¬ ì¤‘: {wav_path}")
            model = whisper.load_model(self.config["whisper_model"])
            result = model.transcribe(wav_path, language="ko")

            with open(transcript_path, "w", encoding="utf-8") as f:
                f.write(result["text"])

            logger.info(f"ğŸ“„ ì „ì‚¬ ê²°ê³¼: {result['text']}")
            return result["text"]
        except Exception as e:
            logger.error(f"ì „ì‚¬ ì‹¤íŒ¨: {e}")
            return None

    def run_mfa_alignment(
        self, wav_path: str, transcript_path: str, output_name: str
    ) -> bool:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬

        Args:
            wav_path: WAV íŒŒì¼ ê²½ë¡œ
            transcript_path: ì „ì‚¬ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            output_name: ì¶œë ¥ íŒŒì¼ ì´ë¦„ (í™•ì¥ì ì œì™¸)

        Returns:
            bool: ì •ë ¬ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")

            # íŒŒì¼ ë³µì‚¬
            shutil.copy(wav_path, os.path.join(self.mfa_input, f"{output_name}.wav"))
            shutil.copy(
                transcript_path, os.path.join(self.mfa_input, f"{output_name}.txt")
            )

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
                "mfa",
                "align",
                self.mfa_input,
                self.lexicon_path,
                self.acoustic_model,
                self.mfa_output,
                "--clean",
                "--no_text_cleaning",
            ]

            result = subprocess.run(
                command, capture_output=True, text=True, check=False
            )

            if result.returncode != 0:
                logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def summarize_textgrid(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ ìŒì†Œ ì •ë³´ ì¶”ì¶œ

        Args:
            path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ìŒì†Œ ì •ë³´ ìš”ì•½ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
            tg = textgrid.TextGrid.fromFile(path)
            summary = []

            for tier in tg.tiers:
                if tier.name.lower() in ["phones", "phoneme", "phone"]:
                    for interval in tier:
                        if interval.mark.strip():
                            summary.append(
                                f"{interval.mark}: {round(interval.minTime, 2)}s ~ {round(interval.maxTime, 2)}s"
                            )

            return "\n".join(summary)
        except Exception as e:
            logger.error(f"TextGrid ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def extract_pronunciation_issues(
        self, learner_text: str, native_text: str, learner_timing: str
    ) -> List[str]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ

        Args:
            learner_text: í•™ìŠµì í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ í…ìŠ¤íŠ¸
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´

        Returns:
            List[str]: ë°œê²¬ëœ ë¬¸ì œì  ëª©ë¡
        """
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ë¬¸ì œ ì¶”ì¶œ
        issues = []

        # 1. í…ìŠ¤íŠ¸ ê¸¸ì´ ì°¨ì´ (ë„ˆë¬´ í¬ë©´ ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„±)
        if len(native_text) > len(learner_text) * 1.2:
            issues.append("ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„± ìˆìŒ")

        # 2. ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
        learner_words = learner_text.split()
        native_words = native_text.split()

        for n_word in native_words:
            if len(n_word) >= 2 and n_word not in learner_text:
                # ë°›ì¹¨ì´ ìˆëŠ” ë‹¨ì–´ë©´ ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê°€ëŠ¥ì„± ì¶”ê°€
                if any(c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…" for c in n_word):
                    issues.append(f"'{n_word}' ë‹¨ì–´ ë°œìŒ ë¬¸ì œ (ë°›ì¹¨ ê´€ë ¨)")

        # 3. ê³µí†µ ìŒì†Œ ë¬¸ì œ (ìŒì†Œ ê¸¸ì´, ìŒìƒ‰ ë“±)
        phoneme_issues = set()
        for line in learner_timing.split("\n"):
            parts = line.split(":")
            if len(parts) >= 2:
                phoneme = parts[0].strip()

                # ëª¨ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã…“", "ã…—", "ã…œ", "ã…¡"]:
                    phoneme_issues.add(f"{phoneme} ëª¨ìŒ ë°œìŒ")

                # ê²½ìŒ/ê²©ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã„²", "ã„¸", "ã…ƒ", "ã…†", "ã…‰", "ã…‹", "ã…Œ", "ã…", "ã…Š"]:
                    phoneme_issues.add(f"{phoneme} ììŒ ë°œìŒ")

        issues.extend(list(phoneme_issues))

        return issues

    def generate_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
    ) -> str:
        """GPT í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            learner_text: í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸
            script_text: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸
            learner_timing: í•™ìŠµì ìŒì†Œ ì •ë ¬ ì •ë³´
            native_timing: ì›ì–´ë¯¼ ìŒì†Œ ì •ë ¬ ì •ë³´

        Returns:
            str: GPT í”„ë¡¬í”„íŠ¸
        """
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒì€ í•œêµ­ì–´ í•™ìŠµìì˜ ë°œí™” ì •ë³´ì™€ ì›ì–´ë¯¼ì˜ ì˜ˆì‹œ ë°œí™” ì •ë³´ì…ë‹ˆë‹¤.

# í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸:
"{learner_text}"

# ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸:
"{native_text}"

# ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸:
"{script_text}"

# í•™ìŠµìì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{learner_timing}

# ì›ì–´ë¯¼ì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{native_timing}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

1. í•™ìŠµìì˜ ë°œìŒì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?
   - êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ

2. í•™ìŠµìì˜ ë°œìŒì—ì„œ ë¶€ì ì ˆí•˜ê²Œ ë„ì–´ ì½ì€ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?  
   - ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

3. ì›ì–´ë¯¼ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ **ë‹¨ì–´ë‚˜ êµ¬ì ˆì—ì„œ** ì†ë„ ì°¨ì´ê°€ ìˆëŠ”ê°€?  
   - ì†ë„ ì •ë³´ë¥¼ ì œì‹œí•  ë•ŒëŠ” ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

4. ë” ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•˜ê¸° ìœ„í•œ íŒì„ ê°„ë‹¨íˆ ì œì‹œ
"""

        # RAGê°€ í™œì„±í™”ëœ ê²½ìš°, ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ ë° ì¶”ê°€
        if self.config["use_rag"] and self.knowledge_base:
            # ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ
            issues = self.extract_pronunciation_issues(
                learner_text, native_text, learner_timing
            )

            # ì¿¼ë¦¬ ìƒì„±
            query = f"í•œêµ­ì–´ ë°œìŒ: {' '.join(issues)}"

            # ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
            relevant_docs = self.knowledge_base.search(query, top_k=3)

            if relevant_docs:
                prompt += "\n\n# ì°¸ê³ í•  ë°œìŒ ì§€ì‹:\n"
                for doc in relevant_docs:
                    prompt += f"- {doc['content']}\n"

                prompt += "\nìœ„ ì°¸ê³  ì§€ì‹ì„ í™œìš©í•˜ì—¬ í•™ìŠµìì—ê²Œ ë” êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”."

        return prompt

    def get_feedback(self, prompt: str) -> Optional[str]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            prompt: GPT í”„ë¡¬í”„íŠ¸

        Returns:
            Optional[str]: ìƒì„±ëœ í”¼ë“œë°± (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")

            if not self.api_key:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            client = OpenAI(api_key=self.api_key)
            response = client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ ë°œìŒ ê°•ì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìê°€ ì™¸êµ­ì¸ì„ì„ ê³ ë ¤í•˜ì—¬ ì‰¬ìš´ ë¬¸ë²• ìš©ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    },
                    {"role": "user", "content": prompt},
                ],
            )

            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def analyze_pronunciation(
        self,
        learner_audio: Optional[str] = None,
        native_audio: Optional[str] = None,
        script: Optional[str] = None,
    ) -> Dict:
        """ë°œìŒ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
            native_audio: ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
            script: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸ (ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼ ë° ìƒíƒœ
        """
        result = {
            "success": False,
            "feedback": None,
            "error": None,
            "learner_text": None,
            "native_text": None,
            "script_text": None,
        }

        try:
            # ì…ë ¥ íŒŒì¼ ì„¤ì •
            if learner_audio:
                self.learner_audio = learner_audio
            if native_audio:
                self.native_audio = native_audio

            # 1. ì˜¤ë””ì˜¤ ë³€í™˜
            if not self.convert_audio(self.learner_audio, self.learner_wav):
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                return result

            if not self.convert_audio(self.native_audio, self.native_wav):
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                return result
            # 2. Whisper ì „ì‚¬
            learner_text = self.transcribe_audio(
                self.learner_wav, self.learner_transcript
            )
            if not learner_text:
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨"
                return result

            native_text = self.transcribe_audio(self.native_wav, self.native_transcript)
            if not native_text:
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨"
                return result

            # ê²°ê³¼ì— ì „ì‚¬ í…ìŠ¤íŠ¸ ì €ì¥
            result["learner_text"] = learner_text
            result["native_text"] = native_text

            # 3. ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© ë˜ëŠ” ì„¤ì •
            if script:
                script_text = script
                # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì—ë„ ì €ì¥
                with open(self.script_path, "w", encoding="utf-8") as f:
                    f.write(script_text)
            else:
                try:
                    with open(self.script_path, "r", encoding="utf-8") as f:
                        script_text = f.read().strip()
                except FileNotFoundError:
                    # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ì–´ë¯¼ ì „ì‚¬ë¥¼ ì‚¬ìš©
                    script_text = native_text
                    with open(self.script_path, "w", encoding="utf-8") as f:
                        f.write(script_text)

            result["script_text"] = script_text

            # 4. MFA ì •ë ¬
            if not self.run_mfa_alignment(
                self.learner_wav, self.learner_transcript, "learner"
            ):
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ì •ë ¬ ì‹¤íŒ¨"
                return result

            if not self.run_mfa_alignment(
                self.native_wav, self.native_transcript, "native"
            ):
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ì •ë ¬ ì‹¤íŒ¨"
                return result

            # 5. TextGrid ìš”ì•½
            learner_timing = self.summarize_textgrid(self.learner_textgrid)
            if not learner_timing:
                result["error"] = "í•™ìŠµì TextGrid ìš”ì•½ ì‹¤íŒ¨"
                return result

            native_timing = self.summarize_textgrid(self.native_textgrid)
            if not native_timing:
                result["error"] = "ì›ì–´ë¯¼ TextGrid ìš”ì•½ ì‹¤íŒ¨"
                return result

            # 6. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.generate_prompt(
                learner_text, native_text, script_text, learner_timing, native_timing
            )

            # 7. GPT í”¼ë“œë°± ìƒì„±
            feedback = self.get_feedback(prompt)
            if not feedback:
                result["error"] = "í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨"
                return result

            # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
            result["success"] = True
            result["feedback"] = feedback

            return result

        except Exception as e:
            logger.error(f"ë°œìŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            result["error"] = str(e)
            return result


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì½”ì¹˜ ì´ˆê¸°í™”
        koach = Koach()

        # ë°œìŒ ë¶„ì„ ì‹¤í–‰
        result = koach.analyze_pronunciation()

        # ê²°ê³¼ ì¶œë ¥
        if result["success"]:
            print("\nğŸ“£ ë°œìŒ í”¼ë“œë°± ê²°ê³¼:\n")
            print(result["feedback"])

            # RAG ê´€ë ¨ ì •ë³´ ì¶œë ¥ (í™œì„±í™”ëœ ê²½ìš°)
            if koach.config["use_rag"] and koach.knowledge_base:
                print("\nğŸ“š ì‚¬ìš©ëœ ì§€ì‹ ë² ì´ìŠ¤ ì •ë³´:")
                print(f"- ë¬¸ì„œ ìˆ˜: {len(koach.knowledge_base.documents)}")
                print(f"- ì„ë² ë”© ëª¨ë¸: {koach.config['embedding_model']}")
        else:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")

    except Exception as e:
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
