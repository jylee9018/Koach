import os
import subprocess
import whisper
from openai import OpenAI
import shutil
from pydub import AudioSegment
import textgrid

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")

# === íŒŒì¼ ê²½ë¡œ ì„¤ì • ===

# ì›ë³¸ ì…ë ¥ íŒŒì¼
LEARNER_AUDIO = "input/learner.m4a"
NATIVE_AUDIO = "input/native.m4a"

# ë³€í™˜ëœ WAV íŒŒì¼
LEARNER_WAV = "wav/learner.wav"
NATIVE_WAV = "wav/native.wav"

# Whisper ì „ì‚¬ ê²°ê³¼
LEARNER_TRANSCRIPT = "wav/learner.txt"
NATIVE_TRANSCRIPT = "wav/native.txt"

# ì •ë‹µ ìŠ¤í¬ë¦½íŠ¸
SCRIPT_PATH = "wav/script.txt"

# MFA ê´€ë ¨ íŒŒì¼
LEXICON_PATH = "models/korean_mfa.dict"
ACOUSTIC_MODEL = "models/korean_mfa.zip"
MFA_INPUT = "mfa_input"
MFA_OUTPUT = "aligned"

LEARNER_TEXTGRID = os.path.join(MFA_OUTPUT, "learner.TextGrid")
NATIVE_TEXTGRID = os.path.join(MFA_OUTPUT, "native.TextGrid")


# === 1. ì˜¤ë””ì˜¤ ë³€í™˜ ===
def convert_audio(input_path, output_path):
    print(f"ğŸ§ ë³€í™˜ ì¤‘: {input_path} â†’ {output_path}")
    audio = AudioSegment.from_file(input_path)
    audio = audio.set_channels(1).set_frame_rate(16000)
    audio.export(output_path, format="wav")
    print("âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ")


# === 2. Whisper ì „ì‚¬ ===
def transcribe_audio(wav_path, transcript_path):
    print(f"ğŸ“ Whisper ì „ì‚¬ ì¤‘: {wav_path}")
    model = whisper.load_model("base")
    result = model.transcribe(wav_path, language="ko")
    with open(transcript_path, "w", encoding="utf-8") as f:
        f.write(result["text"])
    print(f"ğŸ“„ ì „ì‚¬ ê²°ê³¼: {result['text']}")
    return result["text"]


# === 3. MFA ì •ë ¬ ===
def run_mfa_alignment(wav_path, transcript_path, output_name):
    print(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")
    os.makedirs(MFA_INPUT, exist_ok=True)
    os.makedirs(MFA_OUTPUT, exist_ok=True)

    # íŒŒì¼ ë³µì‚¬
    shutil.copy(wav_path, os.path.join(MFA_INPUT, f"{output_name}.wav"))
    shutil.copy(transcript_path, os.path.join(MFA_INPUT, f"{output_name}.txt"))

    # MFA ì •ë ¬ ì‹¤í–‰
    command = [
        "mfa",
        "align",
        MFA_INPUT,
        LEXICON_PATH,
        ACOUSTIC_MODEL,
        MFA_OUTPUT,
        "--clean",
        "--no_text_cleaning",
    ]
    subprocess.run(command, check=True)
    print("âœ… MFA ì •ë ¬ ì™„ë£Œ")


# === 4. TextGrid ìš”ì•½ ===
def summarize_textgrid(path):
    print(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
    tg = textgrid.TextGrid.fromFile(path)
    summary = []
    for tier in tg.tiers:
        if tier.name.lower() in ["phones", "phoneme", "phone"]:
            for interval in tier:
                if interval.mark.strip():
                    summary.append(
                        f"{interval.mark}: {round(interval.minTime, 2)}s ~ {round(interval.maxTime, 2)}s"
                    )
    return "\n".join(summary)


# === 5. GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ===
def generate_prompt(
    learner_text, native_text, script_text, learner_timing, native_timing
):
    prompt = f"""
ë‹¤ìŒì€ í•œêµ­ì–´ í•™ìŠµìì˜ ë°œí™” ì •ë³´ì™€ ì›ì–´ë¯¼ì˜ ì˜ˆì‹œ ë°œí™” ì •ë³´ì…ë‹ˆë‹¤.

# í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸:
"{learner_text}"

# ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸:
"{native_text}"

# ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸:
"{script_text}"

# í•™ìŠµìì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{learner_timing}

# ì›ì–´ë¯¼ì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{native_timing}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

1. í•™ìŠµìì˜ ë°œìŒì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?
   - êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì¤˜.

2. ì›ì–´ë¯¼ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ **ë‹¨ì–´ë‚˜ êµ¬ì ˆì—ì„œ** ì†ë„ ì°¨ì´ê°€ ìˆëŠ”ê°€?  
   - ì†ë„ ì •ë³´ë¥¼ ì œì‹œí•  ë•ŒëŠ” ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ë§í•´ì¤˜.

3. ë” ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•˜ê¸° ìœ„í•œ íŒì„ ê°„ë‹¨íˆ 
"""
    return prompt


# === 6. GPT í˜¸ì¶œ ===
def get_feedback(prompt):
    print("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë°œìŒ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
    )
    return response.choices[0].message.content


# === 7. ì „ì²´ ì‹¤í–‰ ===
def main():
    # ì˜¤ë””ì˜¤ ë³€í™˜
    convert_audio(LEARNER_AUDIO, LEARNER_WAV)
    convert_audio(NATIVE_AUDIO, NATIVE_WAV)

    # Whisper ì „ì‚¬
    learner_text = transcribe_audio(LEARNER_WAV, LEARNER_TRANSCRIPT)
    native_text = transcribe_audio(NATIVE_WAV, NATIVE_TRANSCRIPT)

    # ìŠ¤í¬ë¦½íŠ¸ ë¡œë”©
    with open(SCRIPT_PATH, "r", encoding="utf-8") as f:
        script_text = f.read().strip()

    # MFA ì •ë ¬
    run_mfa_alignment(LEARNER_WAV, LEARNER_TRANSCRIPT, "learner")
    run_mfa_alignment(NATIVE_WAV, NATIVE_TRANSCRIPT, "native")

    # TextGrid ìš”ì•½
    learner_timing = summarize_textgrid(LEARNER_TEXTGRID)
    native_timing = summarize_textgrid(NATIVE_TEXTGRID)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = generate_prompt(
        learner_text, native_text, script_text, learner_timing, native_timing
    )

    # GPT í”¼ë“œë°± ìƒì„±
    feedback = get_feedback(prompt)

    # ì¶œë ¥
    print("\nğŸ“£ ë°œìŒ í”¼ë“œë°± ê²°ê³¼:\n")
    print(feedback)


if __name__ == "__main__":
    main()
