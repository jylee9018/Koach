import os
import subprocess
import whisper
from openai import OpenAI
import shutil
from pydub import AudioSegment
import textgrid
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("Koach")


class Koach:
    """í•œêµ­ì–´ ë°œìŒ í‰ê°€ ë° í”¼ë“œë°± ì‹œìŠ¤í…œ"""

    def __init__(self, config: Optional[Dict] = None):
        """
        Args:
            config: ì„¤ì • íŒŒë¼ë¯¸í„° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        # ê¸°ë³¸ ì„¤ì •
        self.config = {
            # íŒŒì¼ ê²½ë¡œ
            "learner_audio": "input/learner.m4a",
            "native_audio": "input/native.m4a",
            "output_dir": "output",
            "wav_dir": "wav",
            "mfa_input_dir": "mfa_input",
            "mfa_output_dir": "aligned",
            # ëª¨ë¸ ê²½ë¡œ
            "lexicon_path": "models/korean_mfa.dict",
            "acoustic_model": "models/korean_mfa.zip",
            # Whisper ëª¨ë¸ í¬ê¸°
            "whisper_model": "base",
            # OpenAI ëª¨ë¸
            "openai_model": "gpt-4o",
        }

        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if config:
            self.config.update(config)

        # OpenAI API í‚¤ ì„¤ì •
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            logger.warning("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self._setup_paths()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_directories()

    def _setup_paths(self):
        """íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        # ì…ë ¥ íŒŒì¼
        self.learner_audio = self.config["learner_audio"]
        self.native_audio = self.config["native_audio"]

        # ë””ë ‰í† ë¦¬
        self.wav_dir = self.config["wav_dir"]
        self.mfa_input = self.config["mfa_input_dir"]
        self.mfa_output = self.config["mfa_output_dir"]

        # ë³€í™˜ëœ WAV íŒŒì¼
        self.learner_wav = os.path.join(self.wav_dir, "learner.wav")
        self.native_wav = os.path.join(self.wav_dir, "native.wav")

        # Whisper ì „ì‚¬ ê²°ê³¼
        self.learner_transcript = os.path.join(self.wav_dir, "learner.txt")
        self.native_transcript = os.path.join(self.wav_dir, "native.txt")

        # ì •ë‹µ ìŠ¤í¬ë¦½íŠ¸
        self.script_path = os.path.join(self.wav_dir, "script.txt")

        # MFA ê´€ë ¨ íŒŒì¼
        self.lexicon_path = self.config["lexicon_path"]
        self.acoustic_model = self.config["acoustic_model"]

        # TextGrid íŒŒì¼
        self.learner_textgrid = os.path.join(self.mfa_output, "learner.TextGrid")
        self.native_textgrid = os.path.join(self.mfa_output, "native.TextGrid")

    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.wav_dir, exist_ok=True)
        os.makedirs(self.mfa_input, exist_ok=True)
        os.makedirs(self.mfa_output, exist_ok=True)

    def convert_audio(self, input_path: str, output_path: str) -> bool:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            input_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ WAV íŒŒì¼ ê²½ë¡œ

        Returns:
            bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"ğŸ§ ë³€í™˜ ì¤‘: {input_path} â†’ {output_path}")
            audio = AudioSegment.from_file(input_path)
            audio = audio.set_channels(1).set_frame_rate(16000)
            audio.export(output_path, format="wav")
            logger.info("âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, wav_path: str, transcript_path: str) -> Optional[str]:
        """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬

        Args:
            wav_path: WAV íŒŒì¼ ê²½ë¡œ
            transcript_path: ì „ì‚¬ ê²°ê³¼ ì €ì¥ ê²½ë¡œ

        Returns:
            Optional[str]: ì „ì‚¬ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“ Whisper ì „ì‚¬ ì¤‘: {wav_path}")
            model = whisper.load_model(self.config["whisper_model"])
            result = model.transcribe(wav_path, language="ko")

            with open(transcript_path, "w", encoding="utf-8") as f:
                f.write(result["text"])

            logger.info(f"ğŸ“„ ì „ì‚¬ ê²°ê³¼: {result['text']}")
            return result["text"]
        except Exception as e:
            logger.error(f"ì „ì‚¬ ì‹¤íŒ¨: {e}")
            return None

    # def transcribe_audio(self, wav_path: str, transcript_path: str) -> Optional[str]:
    #     """Google Cloud Speech-to-Textë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬

    #     Args:
    #         wav_path: WAV íŒŒì¼ ê²½ë¡œ
    #         transcript_path: ì „ì‚¬ ê²°ê³¼ ì €ì¥ ê²½ë¡œ

    #     Returns:
    #         Optional[str]: ì „ì‚¬ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ None)
    #     """
    #     try:
    #         logger.info(f"ğŸ“ Google STT ì „ì‚¬ ì¤‘: {wav_path}")

    #         # ì¸ì¦ ì •ë³´ íŒŒì¼ ê²½ë¡œ
    #         credentials_path = self.config.get(
    #             "google_credentials", "/Users/jlee/Keys/my-credentials.json"
    #         )

    #         # Google Cloud í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ëª…ì‹œì  ì¸ì¦)
    #         from google.cloud import speech
    #         from google.oauth2 import service_account

    #         credentials = service_account.Credentials.from_service_account_file(
    #             credentials_path
    #         )
    #         client = speech.SpeechClient(credentials=credentials)

    #         # ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
    #         with open(wav_path, "rb") as audio_file:
    #             content = audio_file.read()

    #         audio = speech.RecognitionAudio(content=content)
    #         config = speech.RecognitionConfig(
    #             encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
    #             sample_rate_hertz=16000,
    #             language_code="ko-KR",
    #             enable_automatic_punctuation=True,
    #         )

    #         # ì „ì‚¬ ìš”ì²­
    #         response = client.recognize(config=config, audio=audio)

    #         # ê²°ê³¼ ì²˜ë¦¬
    #         transcript = ""
    #         for result in response.results:
    #             transcript += result.alternatives[0].transcript

    #         # ê²°ê³¼ ì €ì¥
    #         with open(transcript_path, "w", encoding="utf-8") as f:
    #             f.write(transcript)

    #         logger.info(f"ğŸ“„ ì „ì‚¬ ê²°ê³¼: {transcript}")
    #         return transcript
    #     except Exception as e:
    #         logger.error(f"ì „ì‚¬ ì‹¤íŒ¨: {e}")
    #         return None

    def run_mfa_alignment(self, wav_path: str, transcript_path: str, output_name: str) -> bool:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬

        Args:
            wav_path: WAV íŒŒì¼ ê²½ë¡œ
            transcript_path: ì „ì‚¬ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            output_name: ì¶œë ¥ íŒŒì¼ ì´ë¦„ (í™•ì¥ì ì œì™¸)

        Returns:
            bool: ì •ë ¬ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")

            # íŒŒì¼ ë³µì‚¬
            shutil.copy(wav_path, os.path.join(self.mfa_input, f"{output_name}.wav"))
            shutil.copy(
                transcript_path, os.path.join(self.mfa_input, f"{output_name}.txt")
            )

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
     
                "align",
                self.mfa_input,
        lexicon_path,
                self.acoustic_model,
                self.mfa_output,
                "--clean",
                "--no_text_cleaning",
            ]

            result = subprocess.run(
                command, capture_output=True, text=True, check=False
            )

            if result.returncode != 0:
                logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def summarize_textgrid(self, path: str) -> Optional[str]:
       """TextGrid íŒŒì¼ì—ì„œ ìŒì†Œ ì •ë³´ ì¶”ì¶œ

        Args:
            path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ìŒì†Œ ì •ë³´ ìš”ì•½ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
            tg = textgrid.TextGrid.fromFile(path)
            summary = []

            for tier in tg.tiers:
                if tier.name.lower() in ["phones", "phoneme", "phone"]:
                    for interval in tier:
                        if interval.mark.strip():
                            summary.append(
                                f"{interval.mark}: {round(interval.minTime, 2)}s ~ {round(interval.maxTime, 2)}s"
                            )

            return "\n".join(summary)
        except Exception as e:
            logger.error(f"TextGrid ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def generate_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
    ) -> str:
        """GPT í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            learner_text: í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸
            script_text: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸
            learner_timing: í•™ìŠµì ìŒì†Œ ì •ë ¬ ì •ë³´
            native_timing: ì›ì–´ë¯¼ ìŒì†Œ ì •ë ¬ ì •ë³´

        Returns:
            str: GPT í”„ë¡¬í”„íŠ¸
        """
        prompt = f"""
ë‹¤ìŒì€ í•œêµ­ì–´ í•™ìŠµìì˜ ë°œí™” ì •ë³´ì™€ ì›ì–´ë¯¼ì˜ ì˜ˆì‹œ ë°œí™” ì •ë³´ì…ë‹ˆë‹¤.

# í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸:
"{learner_text}"

# ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸:
"{native_text}"

# ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸:
"{script_text}"

# í•™ìŠµìì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{learner_timing}

# ì›ì–´ë¯¼ì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{native_timing}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

1. í•™ìŠµìì˜ ë°œìŒì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?
   - êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ

2. í•™ìŠµìì˜ ë°œìŒì—ì„œ ë¶€ì ì ˆí•˜ê²Œ ë„ì–´ ì½ì€ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?  
   - ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

3. ì›ì–´ë¯¼ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ **ë‹¨ì–´ë‚˜ êµ¬ì ˆì—ì„œ** ì†ë„ ì°¨ì´ê°€ ìˆëŠ”ê°€?  
   - ì†ë„ ì •ë³´ë¥¼ ì œì‹œí•  ë•ŒëŠ” ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

4. ë” ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•˜ê¸° ìœ„í•œ íŒì„ ê°„ë‹¨íˆ ì œì‹œ
"""
        return prompt

    def get_feedback(self, prompt: str) -> Optional[str]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            prompt: GPT í”„ë¡¬í”„íŠ¸

        Returns:
            Optional[str]: ìƒì„±ëœ í”¼ë“œë°± (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")

            if not self.api_key:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            client = OpenAI(api_key=self.api_key)
            response = client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ ë°œìŒ ê°•ì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìê°€ ì™¸êµ­ì¸ì„ì„ ê³ ë ¤í•˜ì—¬ ì‰¬ìš´ ë¬¸ë²• ìš©ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    },
                    {"role": "user", "content": prompt},
                ],
            )

            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def analyze_pronunciation(
        self,
        learner_audio: Optional[str] = None,
        native_audio: Optional[str] = None,
        script: Optional[str] = None,
    ) -> Dict:
        """ë°œìŒ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
            native_audio: ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
            script: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸ (ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼ ë° ìƒíƒœ
        """
        result = {
            "success": False,
            "feedback": None,
            "error": None,
            "learner_text": None,
            "native_text": None,
            "script_text": None,
        }

        try:
            # ì…ë ¥ íŒŒì¼ ì„¤ì •
            if learner_audio:
                self.learner_audio = learner_audio
            if native_audio:
                self.native_audio = native_audio

            # 1. ì˜¤ë””ì˜¤ ë³€í™˜
            if not self.convert_audio(self.learner_audio, self.learner_wav):
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                return result

            if not self.convert_audio(self.native_audio, self.native_wav):
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                return result

            # 2. Whisper ì „ì‚¬
            learner_text = self.transcribe_audio(
                self.learner_wav, self.learner_transcript
            )
            if not learner_text:
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨"
                return result

            native_text = self.transcribe_audio(self.native_wav, self.native_transcript)
            if not native_text:
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨"
                return result

            # ê²°ê³¼ì— ì „ì‚¬ í…ìŠ¤íŠ¸ ì €ì¥
            result["learner_text"] = learner_text
            result["native_text"] = native_text

            # 3. ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© ë˜ëŠ” ì„¤ì •
            if script:
                script_text = script
                # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì—ë„ ì €ì¥
                with open(self.script_path, "w", encoding="utf-8") as f:
                    f.write(script_text)
            else:
                try:
                    with open(self.script_path, "r", encoding="utf-8") as f:
                        script_text = f.read().strip()
                except FileNotFoundError:
                    # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ì–´ë¯¼ ì „ì‚¬ë¥¼ ì‚¬ìš©
                    script_text = native_text
                    with open(self.script_path, "w", encoding="utf-8") as f:
                        f.write(script_text)

            result["script_text"] = script_text

            # 4. MFA ì •ë ¬
            if not self.run_mfa_alignment(
                self.learner_wav, self.learner_transcript, "learner"
            ):
                result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ì •ë ¬ ì‹¤íŒ¨"
                return result

            if not self.run_mfa_alignment(
                self.native_wav, self.native_transcript, "native"
            ):
                result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ì •ë ¬ ì‹¤íŒ¨"
                return result

            # 5. TextGrid ìš”ì•½
            learner_timing = self.summarize_textgrid(self.learner_textgrid)
            if not learner_timing:
                result["error"] = "í•™ìŠµì TextGrid ìš”ì•½ ì‹¤íŒ¨"
                return result

            native_timing = self.summarize_textgrid(self.native_textgrid)
            if not native_timing:
                result["error"] = "ì›ì–´ë¯¼ TextGrid ìš”ì•½ ì‹¤íŒ¨"
                return result

            # 6. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.generate_prompt(
                learner_text, native_text, script_text, learner_timing, native_timing
            )

            # 7. GPT í”¼ë“œë°± ìƒì„±
            feedback = self.get_feedback(prompt)
            if not feedback:
                result["error"] = "í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨"
                return result

            # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
            result["success"] = True
            result["feedback"] = feedback

            return result

        except Exception as e:
            logger.error(f"ë°œìŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            result["error"] = str(e)
            return result


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì½”ì¹˜ ì´ˆê¸°í™”
        koach = Koach()

        # ë°œìŒ ë¶„ì„ ì‹¤í–‰
        result = koach.analyze_pronunciation()

        # ê²°ê³¼ ì¶œë ¥
        if result["success"]:
            print("\nğŸ“£ ë°œìŒ í”¼ë“œë°± ê²°ê³¼:\n")
            print(result["feedback"])
        else:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")

    except Exception as e:
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
