#!/usr/bin/env python3
"""
Koach Beta - í•œêµ­ì–´ ë°œìŒ í‰ê°€ ë° í”¼ë“œë°± ì‹œìŠ¤í…œ (ë‹¨ì¼ íŒŒì¼ ë²„ì „)

ì´ íŒŒì¼ì€ ëª¨ë“  ê¸°ëŠ¥ì´ í¬í•¨ëœ ë‹¨ì¼ ì‹¤í–‰ íŒŒì¼ì…ë‹ˆë‹¤.
ë³„ë„ì˜ ëª¨ë“ˆ ì„¤ì¹˜ ì—†ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•„ìˆ˜ íŒ¨í‚¤ì§€:
    pip install openai whisper-openai pydub textgrid sentence-transformers faiss-cpu numpy

ì‚¬ìš©ë²•:
    python koach_beta.py [learner_audio] [native_audio] [script_text]
    
ì˜ˆì‹œ:
    python koach_beta.py input/learner.m4a input/native.m4a "ì•ˆë…•í•˜ì„¸ìš”"
    python koach_beta.py  # ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©

í™˜ê²½ ë³€ìˆ˜:
    export OPENAI_API_KEY="your_openai_api_key"
"""

import os
import sys
import subprocess
import whisper
from openai import OpenAI
import shutil
from pydub import AudioSegment
import textgrid
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import numpy as np
import json
from sentence_transformers import SentenceTransformer
import faiss
import torch

# =============================================================================
# ë² íƒ€ ë²„ì „ ì„¤ì • (Beta Configuration)
# =============================================================================

BETA_CONFIG = {
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ (beta í´ë” ê¸°ì¤€)
    "learner_audio": "input/learner.m4a",
    "native_audio": "input/native.m4a",
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬  
    "output_dir": "output",
    "wav_dir": "output/wav",
    "mfa_input_dir": "output/mfa_input",
    "mfa_output_dir": "output/aligned",
    
    # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ìƒìœ„ í´ë”ì˜ models ë””ë ‰í† ë¦¬)
    "lexicon_path": "../models/korean_mfa.dict", 
    "acoustic_model": "../models/korean_mfa.zip",
    
    # AI ëª¨ë¸ ì„¤ì •
    "whisper_model": "base",  # tiny, base, small, medium, large
    "openai_model": "gpt-4o",
    
    # RAG ì„¤ì •
    "use_rag": True,
    "knowledge_dir": "knowledge", 
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
}

# =============================================================================
# ë¡œê¹… ì„¤ì • (Logging Configuration)  
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("KoachBeta")


# =============================================================================
# ì§€ì‹ ë² ì´ìŠ¤ í´ë˜ìŠ¤ (Knowledge Base)
# =============================================================================

class KnowledgeBase:
    """í•œêµ­ì–´ ë°œìŒ ì§€ì‹ ë² ì´ìŠ¤"""

    def __init__(
        self,
        knowledge_dir: str = "knowledge",
        embedding_model: str = "paraphrase-multilingual-MiniLM-L12-v2",
    ):
        """
        Args:
            knowledge_dir: ì§€ì‹ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
            embedding_model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        self.knowledge_dir = knowledge_dir
        os.makedirs(knowledge_dir, exist_ok=True)

        # ë¬¸ì„œ ì €ì¥ì†Œ
        self.documents = []
        self.document_ids = []

        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer(embedding_model)

        # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.index = None

        # ê¸°ë³¸ ì§€ì‹ ë¡œë“œ
        self.load_knowledge()

    def load_knowledge(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ë¬¸ì„œ ë¡œë“œ"""
        logger.info("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì¤‘...")

        # ì§€ì‹ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ
        file_paths = list(Path(self.knowledge_dir).glob("*.json"))

        if not file_paths:
            logger.warning("ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€ì‹ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            self.create_default_knowledge()
            file_paths = list(Path(self.knowledge_dir).glob("*.json"))

        # ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
        documents = []
        document_ids = []

        for file_path in file_paths:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                for item in data:
                    if "content" in item and "id" in item:
                        documents.append(item["content"])
                        document_ids.append(item["id"])
            except Exception as e:
                logger.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")

        # ë¬¸ì„œ ì €ì¥
        self.documents = documents
        self.document_ids = document_ids

        # ì„ë² ë”© ìƒì„± ë° ì¸ë±ìŠ¤ êµ¬ì¶•
        self.build_index()

        logger.info(f"âœ… {len(self.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

    def create_default_knowledge(self):
        """ê¸°ë³¸ ì§€ì‹ ìƒì„±"""
        logger.info("ê¸°ë³¸ í•œêµ­ì–´ ë°œìŒ ì§€ì‹ ìƒì„± ì¤‘...")

        # í•œêµ­ì–´ ë°œìŒ ê¸°ë³¸ ì§€ì‹
        basic_knowledge = [
            {
                "id": "consonants_basic",
                "content": "í•œêµ­ì–´ ììŒ(ì´ˆì„±): ã„±(g/k), ã„´(n), ã„·(d/t), ã„¹(r/l), ã…(m), ã…‚(b/p), ã……(s), ã…‡(silent/ng), ã…ˆ(j), ã…Š(ch), ã…‹(k), ã…Œ(t), ã…(p), ã…(h). ê° ììŒì€ ìœ„ì¹˜ì™€ ë°œì„± ë°©ë²•ì— ë”°ë¼ êµ¬ë¶„ëœë‹¤.",
            },
            {
                "id": "vowels_basic",
                "content": "í•œêµ­ì–´ ëª¨ìŒ: ã…(a), ã…“(eo), ã…—(o), ã…œ(u), ã…¡(eu), ã…£(i), ã…(ae), ã…”(e), ã…š(oe), ã…Ÿ(wi). ì… ëª¨ì–‘ê³¼ í˜€ì˜ ìœ„ì¹˜ê°€ ë°œìŒì— ì¤‘ìš”í•˜ë‹¤.",
            },
            {
                "id": "final_consonants",
                "content": "í•œêµ­ì–´ ë°›ì¹¨(ì¢…ì„±): ë°›ì¹¨ì€ ë‹¨ì–´ ëì— ì˜¤ëŠ” ììŒìœ¼ë¡œ, ë°œìŒì´ ì•½í™”ë˜ê±°ë‚˜ ë³€í˜•ë  ìˆ˜ ìˆë‹¤. ì£¼ìš” ë°›ì¹¨ ë°œìŒ: ã„±, ã„´, ã„·, ã„¹, ã…, ã…‚, ã…‡. íŠ¹íˆ ã„±, ã„·, ã…‚ì€ ë‹¨ì–´ ëì—ì„œ ë¶ˆíŒŒìŒìœ¼ë¡œ ë°œìŒí•œë‹¤.",
            },
            {
                "id": "pronunciation_rules",
                "content": "í•œêµ­ì–´ ë°œìŒ ê·œì¹™: 1) ì—°ìŒ í˜„ìƒ: ë°›ì¹¨ì´ ë‹¤ìŒ ìŒì ˆì˜ ì²« ì†Œë¦¬ë¡œ ë„˜ì–´ê°€ëŠ” í˜„ìƒ 2) ììŒ ë™í™”: ì¸ì ‘í•œ ììŒë¼ë¦¬ ì„œë¡œ ì˜í–¥ì„ ì£¼ì–´ ë¹„ìŠ·í•œ ì†Œë¦¬ë¡œ ë³€í•˜ëŠ” í˜„ìƒ 3) êµ¬ê°œìŒí™”: ã„·, ã…Œì´ ã…£ ëª¨ìŒ ì•ì—ì„œ ã…ˆ, ã…Šìœ¼ë¡œ ë³€í•˜ëŠ” í˜„ìƒ 4) ê²½ìŒí™”: íŠ¹ì • í™˜ê²½ì—ì„œ í‰ìŒì´ ê²½ìŒìœ¼ë¡œ ë³€í•˜ëŠ” í˜„ìƒ",
            },
            {
                "id": "common_foreigner_errors",
                "content": "ì™¸êµ­ì¸ í•™ìŠµìë“¤ì˜ í”í•œ ë°œìŒ ì‹¤ìˆ˜: 1) ã…“ì™€ ã…— êµ¬ë³„ ì–´ë ¤ì›€ 2) ã„¹ ë°œìŒ (ì˜ì–´ L/Rê³¼ ë‹¤ë¦„) 3) ë°›ì¹¨ ë°œìŒ ëˆ„ë½ 4) ê²½ìŒ(ã„²,ã„¸,ã…ƒ,ã…†,ã…‰)ê³¼ í‰ìŒ êµ¬ë³„ ì–´ë ¤ì›€ 5) ì¥ë‹¨ìŒ êµ¬ë³„ ë¶€ì¡± 6) ì—°ìŒ ê·œì¹™ ì ìš© ì‹¤íŒ¨",
            },
            {
                "id": "rhythm_intonation",
                "content": "í•œêµ­ì–´ ë¦¬ë“¬ê³¼ ì–µì–‘: í•œêµ­ì–´ëŠ” ìŒì ˆ ë‹¨ìœ„ì˜ ë¦¬ë“¬ì„ ê°€ì§„ë‹¤. ë¬¸ì¥ì˜ ì˜ë¯¸ì— ë”°ë¼ ì–µì–‘ íŒ¨í„´ì´ ë‹¬ë¼ì§„ë‹¤. ì˜ë¬¸ë¬¸ì€ ëì´ ì˜¬ë¼ê°€ê³ , í‰ì„œë¬¸ì€ ë‚´ë ¤ê°„ë‹¤. ê°ì • í‘œí˜„ì— ë”°ë¼ ì–µì–‘ì˜ êµ´ê³¡ì´ ì»¤ì§ˆ ìˆ˜ ìˆë‹¤.",
            },
            {
                "id": "practice_techniques",
                "content": "ë°œìŒ ì—°ìŠµ ê¸°ë²•: 1) ì… ëª¨ì–‘ ê±°ìš¸ë¡œ í™•ì¸í•˜ë©° ì—°ìŠµ 2) ë…¹ìŒí•˜ê³  ì›ì–´ë¯¼ê³¼ ë¹„êµ 3) ëŠë¦¬ê²Œ ë°œìŒí•œ í›„ ì ì°¨ ì†ë„ ë†’ì´ê¸° 4) ìµœì†ŒëŒ€ë¦½ìŒ(ë¹„ìŠ·í•œ ì†Œë¦¬ ë‹¨ì–´) ì—°ìŠµ 5) í˜€ ìœ„ì¹˜ ì˜ì‹í•˜ë©° ë°œìŒí•˜ê¸° 6) ê³¼ì¥ëœ ë°œìŒìœ¼ë¡œ ì‹œì‘í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°ì ˆ",
            },
            {
                "id": "tense_consonants",
                "content": "ê²½ìŒ(ëœì†Œë¦¬) ë°œìŒ: ã„², ã„¸, ã…ƒ, ã…†, ã…‰ëŠ” ì„±ëŒ€ë¥¼ ê¸´ì¥ì‹œí‚¤ê³  ê°•í•˜ê²Œ ë°œìŒí•œë‹¤. í‰ìŒê³¼ ë¹„êµ: 'ê°€ë‹¤(gada)'ì™€ 'ê¹Œë‹¤(kkada)', 'ë°”ë‹¤(bada)'ì™€ 'ë¹ ë‹¤(ppada)'ì˜ ì°¨ì´ ì¸ì‹í•˜ê¸°.",
            },
            {
                "id": "aspirated_consonants",
                "content": "ê²©ìŒ(ê±°ì„¼ì†Œë¦¬) ë°œìŒ: ã…‹, ã…Œ, ã…, ã…ŠëŠ” ê°•í•œ ê³µê¸°ë¥¼ ë‚´ë³´ë‚´ë©° ë°œìŒí•œë‹¤. 'ì¹´ë©”ë¼(kamera)', 'íƒ€ë‹¤(tada)', 'íŒŒë‹¤(pada)', 'ì°¨ë‹¤(chada)'ì—ì„œ ê±°ì„¼ ì†Œë¦¬ë¥¼ ëŠë‚„ ìˆ˜ ìˆë‹¤.",
            },
            {
                "id": "linking_sounds",
                "content": "ì—°ìŒ í˜„ìƒ: ë°›ì¹¨ì´ ìˆëŠ” ë‹¨ì–´ ë’¤ì— ëª¨ìŒìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¡°ì‚¬ë‚˜ ì–´ë¯¸ê°€ ì˜¤ë©´, ë°›ì¹¨ì€ ë‹¤ìŒ ìŒì ˆì˜ ì´ˆì„±ì²˜ëŸ¼ ë°œìŒëœë‹¤. ì˜ˆ: 'ê½ƒì´(ê¼¬ì¹˜)', 'ë°¥ì„(ë°”ë¸”)', 'ì±…ì€(ì±„ê·¼)'",
            },
        ]

        # ì§€ì‹ ì €ì¥
        with open(
            os.path.join(self.knowledge_dir, "basic_pronunciation.json"),
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(basic_knowledge, f, ensure_ascii=False, indent=2)

        logger.info("âœ… ê¸°ë³¸ ì§€ì‹ ìƒì„± ì™„ë£Œ")

    def build_index(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if not self.documents:
            logger.warning("ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë¬¸ì„œ ì„ë² ë”© ìƒì„±
        embeddings = self.model.encode(self.documents)

        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(np.array(embeddings).astype("float32"))

        logger.info(f"âœ… {len(self.documents)}ê°œ ë¬¸ì„œì— ëŒ€í•œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """ì§ˆì˜ì— ê´€ë ¨ëœ ì§€ì‹ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

        Returns:
            List[Dict]: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.index or not self.documents:
            logger.warning("ê²€ìƒ‰í•  ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ì§ˆì˜ ì„ë² ë”©
        query_embedding = self.model.encode([query])

        # ìœ ì‚¬ë„ ê²€ìƒ‰
        scores, indices = self.index.search(
            np.array(query_embedding).astype("float32"),
            k=min(top_k, len(self.documents)),
        )

        # ê²°ê³¼ ì •ë¦¬
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.documents) and idx >= 0:
                results.append(
                    {
                        "id": self.document_ids[idx],
                        "content": self.documents[idx],
                        "score": float(scores[0][i]),
                    }
                )

        return results

    def add_document(self, doc_id: str, content: str):
        """ìƒˆ ë¬¸ì„œ ì¶”ê°€ (ì‹¤ì‹œê°„ ì¶”ê°€ìš©)"""
        self.documents.append(content)
        self.document_ids.append(doc_id)
        
        # ì¸ë±ìŠ¤ ì¬êµ¬ì¶• í•„ìš”
        self.build_index()


# =============================================================================
# ë©”ì¸ ë°œìŒ ë¶„ì„ í´ë˜ìŠ¤ (Main Pronunciation Analysis)
# =============================================================================

class Koach:
    """í•œêµ­ì–´ ë°œìŒ í‰ê°€ ë° í”¼ë“œë°± ì‹œìŠ¤í…œ"""

    def __init__(self, config: Optional[Dict] = None):
        """
        Args:
            config: ì„¤ì • íŒŒë¼ë¯¸í„° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        # ë² íƒ€ ë²„ì „ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        self.config = BETA_CONFIG.copy()

        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if config:
            self.config.update(config)

        # OpenAI API í‚¤ ì„¤ì •
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            logger.warning("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self._setup_paths()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_directories()

        # RAG ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼)
        if self.config["use_rag"]:
            self.knowledge_base = KnowledgeBase(
                knowledge_dir=self.config["knowledge_dir"],
                embedding_model=self.config["embedding_model"],
            )
        else:
            self.knowledge_base = None

    def _setup_paths(self):
        """íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        # ì…ë ¥ íŒŒì¼
        self.learner_audio = self.config["learner_audio"]
        self.native_audio = self.config["native_audio"]

        # ë””ë ‰í† ë¦¬
        self.wav_dir = self.config["wav_dir"]
        self.mfa_input = self.config["mfa_input_dir"]
        self.mfa_output = self.config["mfa_output_dir"]

        # ë³€í™˜ëœ WAV íŒŒì¼
        self.learner_wav = os.path.join(self.wav_dir, "learner.wav")
        self.native_wav = os.path.join(self.wav_dir, "native.wav")

        # Whisper ì „ì‚¬ ê²°ê³¼
        self.learner_transcript = os.path.join(self.wav_dir, "learner.txt")
        self.native_transcript = os.path.join(self.wav_dir, "native.txt")

        # ì •ë‹µ ìŠ¤í¬ë¦½íŠ¸
        self.script_path = os.path.join(self.wav_dir, "script.txt")

        # MFA ê´€ë ¨ íŒŒì¼
        self.lexicon_path = self.config["lexicon_path"]
        self.acoustic_model = self.config["acoustic_model"]

        # TextGrid íŒŒì¼
        self.learner_textgrid = os.path.join(self.mfa_output, "learner.TextGrid")
        self.native_textgrid = os.path.join(self.mfa_output, "native.TextGrid")

    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.wav_dir, exist_ok=True)
        os.makedirs(self.mfa_input, exist_ok=True)
        os.makedirs(self.mfa_output, exist_ok=True)
        os.makedirs(self.config["output_dir"], exist_ok=True)
        if self.config["use_rag"]:
            os.makedirs(self.config["knowledge_dir"], exist_ok=True)

    def convert_audio(self, input_path: str, output_path: str) -> bool:
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            logger.info(f"ğŸ§ ë³€í™˜ ì¤‘: {input_path} â†’ {output_path}")
            
            if not os.path.exists(input_path):
                logger.error(f"ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_path}")
                return False
                
            audio = AudioSegment.from_file(input_path)
            audio = audio.set_channels(1).set_frame_rate(16000)
            audio.export(output_path, format="wav")
            logger.info("âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, wav_path: str, transcript_path: str) -> Optional[str]:
        """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬"""
        try:
            logger.info(f"ğŸ“ Whisper ì „ì‚¬ ì¤‘: {wav_path}")
            model = whisper.load_model(self.config["whisper_model"])
            result = model.transcribe(wav_path, language="ko", word_timestamps=True)

            with open(transcript_path, "w", encoding="utf-8") as f:
                f.write(result["text"])

            logger.info(f"ğŸ“„ ì „ì‚¬ ê²°ê³¼: {result['text']}")
            return result["text"]
        except Exception as e:
            logger.error(f"ì „ì‚¬ ì‹¤íŒ¨: {e}")
            return None

    def run_mfa_alignment(
        self, wav_path: str, transcript_path: str, output_name: str
    ) -> bool:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬"""
        try:
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")

            # MFA ëª¨ë¸ íŒŒì¼ í™•ì¸
            if not os.path.exists(self.lexicon_path):
                logger.error(f"MFA ì‚¬ì „ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.lexicon_path}")
                logger.info("Korean MFA ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
                logger.info("mfa download acoustic korean_mfa")
                logger.info("mfa download dictionary korean_mfa")
                return False

            if not os.path.exists(self.acoustic_model):
                logger.error(f"MFA ìŒì„± ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {self.acoustic_model}")
                return False

            # íŒŒì¼ ë³µì‚¬
            shutil.copy(wav_path, os.path.join(self.mfa_input, f"{output_name}.wav"))
            shutil.copy(
                transcript_path, os.path.join(self.mfa_input, f"{output_name}.txt")
            )

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
                "mfa",
                "align",
                self.mfa_input,
                self.lexicon_path,
                self.acoustic_model,
                self.mfa_output,
                "--clean",
                "--no_text_cleaning",
            ]

            result = subprocess.run(
                command, capture_output=True, text=True, check=False
            )

            if result.returncode != 0:
                logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def summarize_textgrid(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ ì••ì¶•ëœ ìŒì†Œ ì •ë³´ ì¶”ì¶œ"""
        try:
            logger.info(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
            tg = textgrid.TextGrid.fromFile(path)
            
            # ê°„ë‹¨í•œ ìš”ì•½ í˜•íƒœë¡œ ë³€ê²½ (í† í° ìˆ˜ ì ˆì•½)
            phonemes = []
            
            for tier in tg.tiers:
                if hasattr(tier, 'intervals'):
                    for interval in tier.intervals:
                        if interval.mark and interval.mark.strip():
                            duration = round(interval.maxTime - interval.minTime, 2)
                            phonemes.append(f"{interval.mark}({duration}s)")
            
            summary = " | ".join(phonemes)
            logger.info(f"ğŸ“ ìŒì†Œ ìš”ì•½: {summary[:100]}...")
            return summary
            
        except Exception as e:
            logger.error(f"TextGrid ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def extract_pronunciation_issues(
        self, learner_text: str, native_text: str, learner_timing: str
    ) -> List[str]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ (ê°„ì†Œí™” ë²„ì „)"""
        issues = []
        
        # ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ë¹„êµ
        if learner_text != native_text:
            issues.append(f"í…ìŠ¤íŠ¸ ì°¨ì´: '{learner_text}' vs '{native_text}'")
        
        # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if learner_timing:
            issues.append(f"íƒ€ì´ë°: {learner_timing[:200]}...")
            
        return issues

    def generate_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
    ) -> str:
        """GPTìš© ë°œìŒ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì••ì¶•ëœ ë²„ì „)"""
        
        # RAG ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì§€ì‹ ê°€ì ¸ì˜¤ê¸°
        rag_context = ""
        if self.knowledge_base:
            query = f"í•œêµ­ì–´ ë°œìŒ {script_text} êµì • í”¼ë“œë°±"
            search_results = self.knowledge_base.search(query, top_k=2)
            
            if search_results:
                rag_context = "\nì°¸ê³  ì§€ì‹:\n"
                for result in search_results:
                    rag_context += f"- {result['content'][:200]}...\n"

        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ë°œìŒ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í•™ìŠµ ëª©í‘œ ë¬¸ì¥**: {script_text}

**ë¶„ì„ ë°ì´í„°**:
- í•™ìŠµì ë°œìŒ: {learner_text}
- ì›ì–´ë¯¼ ë°œìŒ: {native_text}
- í•™ìŠµì íƒ€ì´ë°: {learner_timing[:300] if learner_timing else 'N/A'}...
- ì›ì–´ë¯¼ íƒ€ì´ë°: {native_timing[:300] if native_timing else 'N/A'}...

{rag_context}

**ìš”ì²­ì‚¬í•­**:
1. í•™ìŠµìì™€ ì›ì–´ë¯¼ ë°œìŒì˜ ì£¼ìš” ì°¨ì´ì  ë¶„ì„
2. êµ¬ì²´ì ì¸ ë°œìŒ êµì • í¬ì¸íŠ¸ ì œì‹œ
3. ì‹¤ì œì ì¸ ì—°ìŠµ ë°©ë²• ì œì•ˆ

**ì‘ë‹µ í˜•ì‹**:
## ğŸ“Š ë°œìŒ ë¶„ì„
[ì£¼ìš” ì°¨ì´ì ]

## ğŸ¯ êµì • í¬ì¸íŠ¸  
[êµ¬ì²´ì ì¸ êµì •ì‚¬í•­]

## ğŸ’¡ ì—°ìŠµ ë°©ë²•
[ì‹¤ìš©ì ì¸ ì—°ìŠµë²•]

ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        return prompt

    def get_feedback(self, prompt: str) -> Optional[str]:
        """OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë°œìŒ í”¼ë“œë°± ìƒì„±"""
        if not self.api_key:
            logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        try:
            logger.info("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")
            
            client = OpenAI(api_key=self.api_key)
            
            response = client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë°œìŒ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            feedback = response.choices[0].message.content
            logger.info("âœ… GPT í”¼ë“œë°± ìƒì„± ì™„ë£Œ")
            return feedback
            
        except Exception as e:
            logger.error(f"GPT í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def analyze_pronunciation(
        self,
        learner_audio: Optional[str] = None,
        native_audio: Optional[str] = None,
        script: Optional[str] = None,
    ) -> Dict:
        """ì „ì²´ ë°œìŒ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        
        result = {
            "status": "started",
            "learner_audio": learner_audio or self.learner_audio,
            "native_audio": native_audio or self.native_audio,
            "script": script,
            "steps": {},
            "errors": []
        }

        try:
            # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜
            logger.info("ğŸ¯ 1ë‹¨ê³„: ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜")
            
            learner_path = learner_audio or self.learner_audio
            native_path = native_audio or self.native_audio
            
            if not self.convert_audio(learner_path, self.learner_wav):
                result["errors"].append("í•™ìŠµì ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨")
                return result
                
            if not self.convert_audio(native_path, self.native_wav):
                result["errors"].append("ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨") 
                return result
                
            result["steps"]["audio_conversion"] = "ì„±ê³µ"

            # 2. ìŒì„± ì¸ì‹
            logger.info("ğŸ¯ 2ë‹¨ê³„: ìŒì„± ì¸ì‹")
            
            learner_text = self.transcribe_audio(self.learner_wav, self.learner_transcript)
            native_text = self.transcribe_audio(self.native_wav, self.native_transcript)
            
            if not learner_text or not native_text:
                result["errors"].append("ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
                return result
                
            result["learner_text"] = learner_text
            result["native_text"] = native_text
            result["steps"]["speech_recognition"] = "ì„±ê³µ"

            # 3. ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
            if script:
                with open(self.script_path, "w", encoding="utf-8") as f:
                    f.write(script)
                result["script_text"] = script

            # 4. MFA ì •ë ¬
            logger.info("ğŸ¯ 3ë‹¨ê³„: MFA ì •ë ¬")
            
            learner_aligned = self.run_mfa_alignment(
                self.learner_wav, self.learner_transcript, "learner"
            )
            native_aligned = self.run_mfa_alignment(
                self.native_wav, self.native_transcript, "native"
            )
            
            if not learner_aligned or not native_aligned:
                logger.warning("MFA ì •ë ¬ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                result["steps"]["mfa_alignment"] = "ì‹¤íŒ¨"
                learner_timing = ""
                native_timing = ""
            else:
                result["steps"]["mfa_alignment"] = "ì„±ê³µ"
                
                # TextGrid ìš”ì•½
                learner_timing = self.summarize_textgrid(self.learner_textgrid) or ""
                native_timing = self.summarize_textgrid(self.native_textgrid) or ""

            result["learner_timing"] = learner_timing
            result["native_timing"] = native_timing

            # 5. ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ
            logger.info("ğŸ¯ 4ë‹¨ê³„: ë°œìŒ ë¶„ì„")
            
            pronunciation_issues = self.extract_pronunciation_issues(
                learner_text, native_text, learner_timing
            )
            result["pronunciation_issues"] = pronunciation_issues

            # 6. GPT í”¼ë“œë°± ìƒì„±
            logger.info("ğŸ¯ 5ë‹¨ê³„: GPT í”¼ë“œë°± ìƒì„±")
            
            prompt = self.generate_prompt(
                learner_text, native_text, script or "ì•Œ ìˆ˜ ì—†ìŒ",
                learner_timing, native_timing
            )
            
            gpt_feedback = self.get_feedback(prompt)
            result["gpt_feedback"] = gpt_feedback
            result["prompt_used"] = prompt

            if gpt_feedback:
                result["steps"]["gpt_feedback"] = "ì„±ê³µ"
            else:
                result["steps"]["gpt_feedback"] = "ì‹¤íŒ¨"

            result["status"] = "ì™„ë£Œ"
            logger.info("ğŸ‰ ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")

        except Exception as e:
            logger.error(f"ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜: {e}")
            result["errors"].append(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}")
            result["status"] = "ì‹¤íŒ¨"

        return result


# =============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Main Execution)
# =============================================================================

def print_usage():
    """ì‚¬ìš©ë²• ì¶œë ¥"""
    print("""
ğŸ¤ Koach Beta - í•œêµ­ì–´ ë°œìŒ ë¶„ì„ ì‹œìŠ¤í…œ

ì‚¬ìš©ë²•:
    python koach_beta.py [learner_audio] [native_audio] [script_text]
    python koach_beta.py  # ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©

ì˜ˆì‹œ:
    python koach_beta.py input/learner.m4a input/native.m4a "ì•ˆë…•í•˜ì„¸ìš”"
    python koach_beta.py input/my_voice.wav input/teacher.wav "í•œêµ­ì–´ ë°œìŒ ì—°ìŠµ"

í•„ìˆ˜ ì„¤ì •:
    export OPENAI_API_KEY="your_openai_api_key"

í•„ìˆ˜ íŒ¨í‚¤ì§€:
    pip install openai whisper-openai pydub textgrid sentence-transformers faiss-cpu numpy

MFA ëª¨ë¸ (ì„ íƒì‚¬í•­):
    mfa download acoustic korean_mfa
    mfa download dictionary korean_mfa
    """)

def check_requirements():
    """í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
    errors = []
    
    # OpenAI API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        errors.append("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
    required_dirs = ["input", "output", "knowledge"]
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name, exist_ok=True)
            logger.info(f"ğŸ“ {dir_name} ë””ë ‰í† ë¦¬ ìƒì„±ë¨")
    
    return errors

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Koach Beta - í•œêµ­ì–´ ë°œìŒ ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) == 4:
        learner_audio = sys.argv[1]
        native_audio = sys.argv[2] 
        script_text = sys.argv[3]
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        config = BETA_CONFIG.copy()
        config["learner_audio"] = learner_audio
        config["native_audio"] = native_audio
        
        logger.info(f"ğŸ“ ì…ë ¥ íŒŒì¼: {learner_audio}, {native_audio}")
        logger.info(f"ğŸ“ ìŠ¤í¬ë¦½íŠ¸: {script_text}")
        
    elif len(sys.argv) == 1:
        # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        config = BETA_CONFIG.copy()
        script_text = "ì•ˆë…•í•˜ì„¸ìš”"  # ê¸°ë³¸ ìŠ¤í¬ë¦½íŠ¸
        
        logger.info("ğŸ“ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©")
        logger.info(f"ğŸ“ ê¸°ë³¸ ìŠ¤í¬ë¦½íŠ¸: {script_text}")
        
    else:
        print_usage()
        return

    # ìš”êµ¬ì‚¬í•­ í™•ì¸
    requirement_errors = check_requirements()
    if requirement_errors:
        for error in requirement_errors:
            print(error)
        print("\nì„¤ì •ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # Koach ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        logger.info("ğŸ”§ Koach ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        koach = Koach(config)
        
        # ë°œìŒ ë¶„ì„ ì‹¤í–‰
        logger.info("ğŸ¯ ë°œìŒ ë¶„ì„ ì‹œì‘...")
        result = koach.analyze_pronunciation(
            learner_audio=config.get("learner_audio"),
            native_audio=config.get("native_audio"), 
            script=script_text
        )
        
        if result and result.get("status") == "ì™„ë£Œ":
            # í„°ë¯¸ë„ ê²°ê³¼ ì¶œë ¥
            print("\n" + "="*60)
            print("ğŸ¯ ë°œìŒ ë¶„ì„ ê²°ê³¼")
            print("="*60)
            
            if result.get("gpt_feedback"):
                print("\nğŸ“‹ GPT ë°œìŒ í”¼ë“œë°±:")
                print("-" * 50)
                print(result["gpt_feedback"])
            else:
                print("\nâš ï¸ GPT í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
            # ê¸°ë³¸ ë¶„ì„ ì •ë³´
            print(f"\nğŸ“Š ê¸°ë³¸ ë¶„ì„ ì •ë³´:")
            print(f"  í•™ìŠµì ë°œìŒ: {result.get('learner_text', 'N/A')}")
            print(f"  ì›ì–´ë¯¼ ë°œìŒ: {result.get('native_text', 'N/A')}")
            print(f"  ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸: {result.get('script_text', script_text)}")
            
            # ì²˜ë¦¬ ë‹¨ê³„ ìƒíƒœ
            print(f"\nğŸ”§ ì²˜ë¦¬ ë‹¨ê³„ ìƒíƒœ:")
            for step, status in result.get("steps", {}).items():
                status_icon = "âœ…" if status == "ì„±ê³µ" else "âŒ" if status == "ì‹¤íŒ¨" else "âš ï¸"
                print(f"  {status_icon} {step}: {status}")
            
            # JSON ê²°ê³¼ ì €ì¥
            output_file = os.path.join(config["output_dir"], "analysis_result.json")
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
            
        else:
            print("\nâŒ ë¶„ì„ ì‹¤íŒ¨")
            if result and result.get("errors"):
                print("ì˜¤ë¥˜ ë‚´ìš©:")
                for error in result["errors"]:
                    print(f"  - {error}")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
    print("\nğŸ‘‹ Koach Beta ì¢…ë£Œ")

if __name__ == "__main__":
    main()
