import os
import logging
import json
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List
import shutil
import subprocess
import librosa
import textgrid
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import faiss
from dotenv import load_dotenv

from utils.audio import (
    convert_audio,
    transcribe_audio,
    extract_audio_segment,
    normalize_audio,
    get_audio_duration,
    get_audio_info,
)
from utils.text import (
    summarize_textgrid,
    extract_word_boundaries,
    align_text_with_audio,
    extract_phoneme_features,
    compare_phoneme_sequences,
)
from core.prosody import ProsodyAnalyzer
from core.knowledge_base import KnowledgeBase
from config.settings import CURRENT_CONFIG, PATHS

logger = logging.getLogger(__name__)


class Koach:
    """í•œêµ­ì–´ ë°œìŒ êµì • ë„ìš°ë¯¸"""

    def __init__(self, config: Optional[Dict] = None):
        """ì´ˆê¸°í™”

        Args:
            config: ì‚¬ìš©ì ì„¤ì •
        """
        # ìƒìœ„ í´ë”ì˜ .env íŒŒì¼ ë¡œë“œ
        env_path = Path(__file__).parent.parent.parent / '.env'
        load_dotenv(env_path)
        
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            logger.warning("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = Path(__file__).parent.parent / "output"
        self.output_dir.mkdir(exist_ok=True)

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.temp_dir = Path(__file__).parent.parent / "temp"
        self.temp_dir.mkdir(exist_ok=True)

        # ê¸°ë³¸ ì„¤ì •
        self.config = {
            # Whisper ëª¨ë¸ ì„¤ì •
            "whisper_model": "base",
            "language": "ko",
            # OpenAI ëª¨ë¸
            "openai_model": "gpt-4o",
            # RAG ì„¤ì •
            "use_rag": True,
            "knowledge_dir": "knowledge",
            "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
        }

        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if config:
            self.config.update(config)

        # íŒŒì¼ ê²½ë¡œ ì„¤ì • (settings.pyì˜ PATHS ì‚¬ìš©)
        self.learner_audio = PATHS["learner_audio"]
        self.native_audio = PATHS["native_audio"]
        self.learner_wav = PATHS["learner_wav"]
        self.native_wav = PATHS["native_wav"]
        self.learner_transcript = PATHS["learner_transcript"]
        self.native_transcript = PATHS["native_transcript"]
        self.script_path = PATHS["script_path"]
        self.learner_textgrid = PATHS["learner_textgrid"]
        self.native_textgrid = PATHS["native_textgrid"]
        self.lexicon_path = PATHS["lexicon_path"]
        self.acoustic_model = PATHS["acoustic_model"]
        self.mfa_input = PATHS["mfa_input"]
        self.mfa_output = PATHS["mfa_output"]

        # RAG ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼)
        if self.config["use_rag"]:
            self.knowledge_base = KnowledgeBase(
                knowledge_dir=self.config["knowledge_dir"],
                embedding_model=self.config["embedding_model"],
            )
        else:
            self.knowledge_base = None

        self.model_name = "base"
        self.prosody_analyzer = ProsodyAnalyzer()

    def analyze_pronunciation(
        self,
        learner_audio: Optional[str] = None,
        native_audio: Optional[str] = None,
        script: Optional[str] = None,
        visualize: bool = True,
    ) -> Dict:
        """ë°œìŒ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            native_audio: ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            script: ìŠ¤í¬ë¦½íŠ¸ (ì„ íƒì‚¬í•­)
            visualize: ì‹œê°í™” ì—¬ë¶€

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
        """
        result = {
            "learner": {},
            "native": {},
            "comparison": {},
            "feedback": None
        }

        try:
            # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ (.m4a -> .wav)
            if learner_audio:
                self.learner_wav = self.convert_audio(learner_audio)
                if not self.learner_wav:
                    result["error"] = "í•™ìŠµì ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                    return result

            if native_audio:
                self.native_wav = self.convert_audio(native_audio)
                if not self.native_wav:
                    result["error"] = "ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨"
                    return result

            # 2. Whisperë¡œ ìŒì„± ì¸ì‹
            if self.learner_wav:
                learner_result = transcribe_audio(self.learner_wav)
                if not learner_result:
                    result["error"] = "í•™ìŠµì ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
                    return result
                result["learner"]["transcription"] = learner_result

            if self.native_wav:
                native_result = transcribe_audio(self.native_wav)
                if not native_result:
                    result["error"] = "ì›ì–´ë¯¼ ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
                    return result
                result["native"]["transcription"] = native_result

            # 3. MFA ì •ë ¬
            if self.learner_wav and learner_result:
                learner_timing = self.align_audio(
                    self.learner_wav,
                    learner_result["text"],
                    "learner"
                )
                if not learner_timing:
                    result["error"] = "í•™ìŠµì ì •ë ¬ ì‹¤íŒ¨"
                    return result
                result["learner"]["timing"] = learner_timing

            if self.native_wav and native_result:
                native_timing = self.align_audio(
                    self.native_wav,
                    native_result["text"],
                    "native"
                )
                if not native_timing:
                    result["error"] = "ì›ì–´ë¯¼ ì •ë ¬ ì‹¤íŒ¨"
                    return result
                result["native"]["timing"] = native_timing

            # 4. ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ
            if learner_result and native_result:
                issues = self.extract_pronunciation_issues(
                    learner_result,
                    native_result,
                    learner_timing,
                    native_timing
                )
                result["comparison"]["issues"] = issues

            # 5. ì–µì–‘/ê°•ì„¸ ë¶„ì„
            if self.learner_wav and self.native_wav:
                prosody_result = self.analyze_prosody(
                    self.learner_wav,
                    self.native_wav,
                    learner_text=learner_result["text"],
                    learner_timing=learner_timing,
                    visualize=visualize
                )
                if not prosody_result:
                    result["error"] = "ì–µì–‘/ê°•ì„¸ ë¶„ì„ ì‹¤íŒ¨"
                    return result
                result["comparison"]["prosody"] = prosody_result

            # 6. LLM í”¼ë“œë°± ìƒì„±
            if result["comparison"] and learner_result and native_result:
                # TextGrid ìš”ì•½ ìƒì„±
                learner_textgrid_path = self.mfa_output / "learner" / f"{Path(self.learner_wav).stem}.TextGrid"
                native_textgrid_path = self.mfa_output / "native" / f"{Path(self.native_wav).stem}.TextGrid"
                
                learner_timing_summary = self.summarize_textgrid(str(learner_textgrid_path))
                native_timing_summary = self.summarize_textgrid(str(native_textgrid_path))
                
                if learner_timing_summary and native_timing_summary:
                    # ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    prompt = self.generate_detailed_prompt(
                        learner_result["text"],
                        native_result["text"],
                        native_result["text"],  # ìŠ¤í¬ë¦½íŠ¸ë¡œ ì›ì–´ë¯¼ í…ìŠ¤íŠ¸ ì‚¬ìš©
                        learner_timing_summary,
                        native_timing_summary,
                        result["comparison"].get("prosody")
                    )
                    
                    # OpenAI APIë¡œ í”¼ë“œë°± ìƒì„±
                    detailed_feedback = self.get_feedback(prompt)
                    
                    if detailed_feedback:
                        result["feedback"] = {
                            "summary": "ìƒì„¸í•œ ë°œìŒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                            "detailed_analysis": detailed_feedback,
                            "prompt_used": prompt
                        }
                    else:
                        # ëŒ€ì²´ í”¼ë“œë°±
                        result["feedback"] = self._generate_simple_feedback(result)
                else:
                    # ëŒ€ì²´ í”¼ë“œë°±
                    result["feedback"] = self._generate_simple_feedback(result)

            # ì„±ê³µ ì‹œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result["success"] = True
            result["timestamp"] = __import__("datetime").datetime.now().isoformat()
            result["processing_info"] = {
                "whisper_model": self.config.get("whisper_model", "base"),
                "openai_model": self.config.get("openai_model", "gpt-4o"),
                "rag_enabled": self.config.get("use_rag", False),
                "visualization_enabled": visualize
            }
            
            return result

        except Exception as e:
            logger.error(f"ë°œìŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            result["error"] = str(e)
            result["timestamp"] = __import__("datetime").datetime.now().isoformat()
            return result

    def run_mfa_alignment(
        self, wav_path: str, transcript_path: str, output_name: str
    ) -> bool:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬"""
        try:
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")

            # MFA ì…ë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
            mfa_input_dir = self.mfa_input / output_name
            mfa_input_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ë³µì‚¬ (ê²½ë¡œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ)
            target_wav = str(mfa_input_dir / f"{output_name}.wav")
            target_txt = str(mfa_input_dir / f"{output_name}.txt")

            if str(wav_path) != target_wav:
                shutil.copy(wav_path, target_wav)
            if str(transcript_path) != target_txt:
                shutil.copy(transcript_path, target_txt)

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
                "mfa",
                "align",
                str(mfa_input_dir),
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output),
                "--clean",
            ]

            result = subprocess.run(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=False,
            )

            if result.returncode != 0:
                logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def _analyze_phonemes(
        self,
        textgrid_path: str,
    ) -> Optional[Dict[str, Any]]:
        """ìŒì†Œ ë¶„ì„

        Args:
            textgrid_path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[Dict[str, Any]]: ìŒì†Œ ë¶„ì„ ê²°ê³¼
        """
        try:
            # TextGrid ìš”ì•½
            summary = self.summarize_textgrid(textgrid_path)

            # ë‹¨ì–´ ê²½ê³„ ì¶”ì¶œ
            word_boundaries = extract_word_boundaries(textgrid_path)

            # ìŒì†Œ íŠ¹ì§• ì¶”ì¶œ
            phoneme_features = extract_phoneme_features(textgrid_path)

            return {
                "summary": summary,
                "word_boundaries": word_boundaries,
                "phoneme_features": phoneme_features,
            }

        except Exception as e:
            logger.error(f"ìŒì†Œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def _compare_with_reference(
        self,
        learner_audio: str,
        reference_audio: str,
        learner_textgrid: str,
    ) -> Optional[Dict[str, Any]]:
        """ì°¸ì¡° ì˜¤ë””ì˜¤ì™€ ë¹„êµ

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            reference_audio: ì°¸ì¡° ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            learner_textgrid: í•™ìŠµì TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[Dict[str, Any]]: ë¹„êµ ê²°ê³¼
        """
        try:
            # ì°¸ì¡° ì˜¤ë””ì˜¤ ì²˜ë¦¬
            ref_path = Path(reference_audio)
            ref_wav = self.temp_dir / f"{ref_path.stem}.wav"

            if not convert_audio(
                reference_audio,
                str(ref_wav),
                sample_rate=CURRENT_CONFIG["audio"]["sample_rate"],
                channels=CURRENT_CONFIG["audio"]["channels"],
            ):
                raise RuntimeError("ì°¸ì¡° ì˜¤ë””ì˜¤ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # ì°¸ì¡° ì˜¤ë””ì˜¤ MFA ì •ë ¬
            ref_mfa_output = self.aligned_dir / ref_path.stem
            if not self.run_mfa_alignment(str(ref_wav), str(ref_wav), ref_path.stem):
                raise RuntimeError("ì°¸ì¡° ì˜¤ë””ì˜¤ MFA ì •ë ¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            ref_textgrid = ref_mfa_output / f"{ref_path.stem}.TextGrid"

            # ìŒì†Œ ì‹œí€€ìŠ¤ ë¹„êµ
            phoneme_comparison = compare_phoneme_sequences(
                learner_textgrid,
                str(ref_textgrid),
            )

            # ìš´ìœ¨ ë¹„êµ
            prosody_comparison = self.prosody_analyzer.compare_prosody(
                learner_audio,
                str(ref_wav),
            )

            return {
                "phoneme_comparison": phoneme_comparison,
                "prosody_comparison": prosody_comparison,
            }

        except Exception as e:
            logger.error(f"ì°¸ì¡° ì˜¤ë””ì˜¤ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def _generate_feedback(
        self,
        phoneme_analysis: Dict[str, Any],
        prosody_analysis: Dict[str, Any],
        comparison: Optional[Dict[str, Any]] = None,
    ) -> List[Dict[str, Any]]:
        """í”¼ë“œë°± ìƒì„±

        Args:
            phoneme_analysis: ìŒì†Œ ë¶„ì„ ê²°ê³¼
            prosody_analysis: ìš´ìœ¨ ë¶„ì„ ê²°ê³¼
            comparison: ì°¸ì¡° ì˜¤ë””ì˜¤ ë¹„êµ ê²°ê³¼ (ì„ íƒì‚¬í•­)

        Returns:
            List[Dict[str, Any]]: í”¼ë“œë°± ëª©ë¡
        """
        feedback = []

        # ìŒì†Œ í”¼ë“œë°±
        if phoneme_analysis:
            # ìŒì†Œ ê¸¸ì´ í”¼ë“œë°±
            phoneme_features = phoneme_analysis["phoneme_features"]
            if phoneme_features["mean_duration"] < 0.05:
                feedback.append(
                    {
                        "type": "phoneme_duration",
                        "level": "warning",
                        "message": "ìŒì†Œ ë°œìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ê° ìŒì†Œë¥¼ ë” ê¸¸ê²Œ ë°œìŒí•´ë³´ì„¸ìš”.",
                    }
                )

            # ìŒì†Œ ê°„ê²© í”¼ë“œë°±
            if phoneme_features["mean_gap"] > 0.1:
                feedback.append(
                    {
                        "type": "phoneme_gap",
                        "level": "warning",
                        "message": "ìŒì†Œ ì‚¬ì´ì˜ ê°„ê²©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ìŒì†Œë¥¼ ë” ì—°ì†ì ìœ¼ë¡œ ë°œìŒí•´ë³´ì„¸ìš”.",
                    }
                )

        # ìš´ìœ¨ í”¼ë“œë°±
        if prosody_analysis:
            # í”¼ì¹˜ í”¼ë“œë°±
            pitch_stats = prosody_analysis["pitch"]["statistics"]
            if pitch_stats["std"] < 10:
                feedback.append(
                    {
                        "type": "pitch_variation",
                        "level": "info",
                        "message": "ìŒë†’ì´ ë³€í™”ê°€ ì ìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ ìŒë†’ì´ë¡œ ë°œìŒí•´ë³´ì„¸ìš”.",
                    }
                )

            # ê°•ì„¸ í”¼ë“œë°±
            if prosody_analysis["energy"]["stress_count"] < 2:
                feedback.append(
                    {
                        "type": "stress",
                        "level": "info",
                        "message": "ë‹¨ì–´ ê°•ì„¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ë‹¨ì–´ì— ë” ê°•ì„¸ë¥¼ ì£¼ì–´ ë°œìŒí•´ë³´ì„¸ìš”.",
                    }
                )

        # ì°¸ì¡° ì˜¤ë””ì˜¤ ë¹„êµ í”¼ë“œë°±
        if comparison:
            # ìŒì†Œ ì¼ì¹˜ë„ í”¼ë“œë°±
            phoneme_comparison = comparison["phoneme_comparison"]
            if phoneme_comparison["match_rate"] < 0.8:
                feedback.append(
                    {
                        "type": "phoneme_match",
                        "level": "warning",
                        "message": "ìŒì†Œ ë°œìŒì´ ì°¸ì¡° ë°œìŒê³¼ ë§ì´ ë‹¤ë¦…ë‹ˆë‹¤. ê° ìŒì†Œì˜ ë°œìŒì„ ë” ì •í™•í•˜ê²Œ í•´ë³´ì„¸ìš”.",
                    }
                )

            # ìš´ìœ¨ ì°¨ì´ í”¼ë“œë°±
            prosody_comparison = comparison["prosody_comparison"]
            if abs(prosody_comparison["pitch"]["mean_diff"]) > 20:
                feedback.append(
                    {
                        "type": "pitch_difference",
                        "level": "info",
                        "message": "ì „ì²´ì ì¸ ìŒë†’ì´ê°€ ì°¸ì¡° ë°œìŒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ìŒë†’ì´ë¥¼ ì¡°ì ˆí•´ë³´ì„¸ìš”.",
                    }
                )

        return feedback

    def _visualize_results(
        self,
        learner_audio: str,
        reference_audio: Optional[str],
        learner_textgrid: str,
        phoneme_analysis: Dict[str, Any],
        prosody_analysis: Dict[str, Any],
        comparison: Optional[Dict[str, Any]] = None,
    ) -> List[str]:
        """ê²°ê³¼ ì‹œê°í™”

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            reference_audio: ì°¸ì¡° ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            learner_textgrid: í•™ìŠµì TextGrid íŒŒì¼ ê²½ë¡œ
            phoneme_analysis: ìŒì†Œ ë¶„ì„ ê²°ê³¼
            prosody_analysis: ìš´ìœ¨ ë¶„ì„ ê²°ê³¼
            comparison: ì°¸ì¡° ì˜¤ë””ì˜¤ ë¹„êµ ê²°ê³¼ (ì„ íƒì‚¬í•­)

        Returns:
            List[str]: ì‹œê°í™” ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ëª©ë¡
        """
        visualization_paths = []

        try:
            # 1. ìŒì†Œ ì‹œê°í™”
            phoneme_plot_path = self.output_dir / "phoneme_analysis.png"
            self._plot_phoneme_analysis(
                phoneme_analysis,
                str(phoneme_plot_path),
            )
            visualization_paths.append(str(phoneme_plot_path))

            # 2. ìš´ìœ¨ ì‹œê°í™”
            prosody_plot_path = self.output_dir / "prosody_analysis.png"
            self.prosody_analyzer.visualize_prosody(
                learner_audio,
                reference_audio,
                str(prosody_plot_path),
            )
            visualization_paths.append(str(prosody_plot_path))

            # 3. ë¹„êµ ì‹œê°í™” (ì°¸ì¡° ì˜¤ë””ì˜¤ê°€ ìˆëŠ” ê²½ìš°)
            if comparison:
                comparison_plot_path = self.output_dir / "comparison_analysis.png"
                self._plot_comparison_analysis(
                    comparison,
                    str(comparison_plot_path),
                )
                visualization_paths.append(str(comparison_plot_path))

            return visualization_paths

        except Exception as e:
            logger.error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return []

    def _plot_phoneme_analysis(
        self,
        phoneme_analysis: Dict[str, Any],
        output_path: str,
    ) -> None:
        """ìŒì†Œ ë¶„ì„ ì‹œê°í™”

        Args:
            phoneme_analysis: ìŒì†Œ ë¶„ì„ ê²°ê³¼
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        import matplotlib.pyplot as plt

        # ìŒì†Œ ê¸¸ì´ ë¶„í¬
        phoneme_features = phoneme_analysis["phoneme_features"]
        durations = [p["duration"] for p in phoneme_features["phonemes"]]

        plt.figure(figsize=CURRENT_CONFIG["visualization"]["figsize"])
        plt.hist(durations, bins=20)
        plt.title("ìŒì†Œ ê¸¸ì´ ë¶„í¬")
        plt.xlabel("ê¸¸ì´ (ì´ˆ)")
        plt.ylabel("ë¹ˆë„")
        plt.savefig(output_path, dpi=CURRENT_CONFIG["visualization"]["dpi"])
        plt.close()

    def _plot_comparison_analysis(
        self,
        comparison: Dict[str, Any],
        output_path: str,
    ) -> None:
        """ë¹„êµ ë¶„ì„ ì‹œê°í™”

        Args:
            comparison: ë¹„êµ ë¶„ì„ ê²°ê³¼
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        import matplotlib.pyplot as plt

        # ìŒì†Œ ì¼ì¹˜ë„
        phoneme_comparison = comparison["phoneme_comparison"]
        match_rate = phoneme_comparison["match_rate"]

        # ìš´ìœ¨ ì°¨ì´
        prosody_comparison = comparison["prosody_comparison"]
        pitch_diff = prosody_comparison["pitch"]["mean_diff"]
        energy_diff = prosody_comparison["energy"]["mean_diff"]

        # ì‹œê°í™”
        plt.figure(figsize=CURRENT_CONFIG["visualization"]["figsize"])

        # ìŒì†Œ ì¼ì¹˜ë„
        plt.subplot(1, 3, 1)
        plt.bar(["ì¼ì¹˜ë„"], [match_rate * 100])
        plt.title("ìŒì†Œ ì¼ì¹˜ë„")
        plt.ylabel("ì¼ì¹˜ë„ (%)")
        plt.ylim(0, 100)

        # í”¼ì¹˜ ì°¨ì´
        plt.subplot(1, 3, 2)
        plt.bar(["í”¼ì¹˜ ì°¨ì´"], [pitch_diff])
        plt.title("í”¼ì¹˜ ì°¨ì´")
        plt.ylabel("ì°¨ì´ (Hz)")

        # ì—ë„ˆì§€ ì°¨ì´
        plt.subplot(1, 3, 3)
        plt.bar(["ì—ë„ˆì§€ ì°¨ì´"], [energy_diff])
        plt.title("ì—ë„ˆì§€ ì°¨ì´")
        plt.ylabel("ì°¨ì´ (dB)")

        plt.tight_layout()
        plt.savefig(output_path, dpi=CURRENT_CONFIG["visualization"]["dpi"])
        plt.close()

    def analyze_prosody(
        self,
        learner_audio: str,
        native_audio: str,
        learner_text: str = None,
        learner_timing: str = None,
        visualize: bool = True,
    ) -> Dict:
        """ì–µì–‘/ê°•ì„¸ ë¶„ì„

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            native_audio: ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            learner_text: í•™ìŠµì ì „ì‚¬ í…ìŠ¤íŠ¸
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´
            visualize: ì‹œê°í™” ì—¬ë¶€

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
        """
        try:
            # ProsodyAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            analyzer = ProsodyAnalyzer()

            # ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ë¡œ ì„ê³„ê°’ ì¡°ì •
            analyzer.adjust_thresholds(native_audio)

            # ì–µì–‘/ê°•ì„¸ ë¹„êµ (learner_textì™€ learner_timing ì œì™¸)
            result = analyzer.compare_prosody(
                learner_audio=learner_audio, reference_audio=native_audio
            )

            # ì‹œê°í™”
            if visualize:
                output_path = self.output_dir / "prosody_comparison.png"
                analyzer.visualize_prosody(
                    learner_audio=learner_audio,
                    reference_audio=native_audio,
                    output_path=str(output_path),
                )
                result["visualization"] = str(output_path)

            return result

        except Exception as e:
            logger.error(f"ì–µì–‘/ê°•ì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def _extract_pitch(self, segment: np.ndarray, sr: int) -> float:
        """ìŒì†Œ êµ¬ê°„ì˜ í”¼ì¹˜ ì¶”ì¶œ"""
        try:
            if len(segment) < 2:
                return 0.0

            # librosaì˜ í”¼ì¹˜ ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
            pitches, magnitudes = librosa.piptrack(y=segment, sr=sr)
            if len(pitches) > 0:
                return np.mean(pitches[magnitudes > np.median(magnitudes)])
            return 0.0
        except Exception as e:
            logger.error(f"í”¼ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0

    def _extract_pitch_contour(self, y: np.ndarray, sr: int) -> np.ndarray:
        """ì „ì²´ ì˜¤ë””ì˜¤ì˜ í”¼ì¹˜ ìœ¤ê³½ì„  ì¶”ì¶œ"""
        try:
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
            if len(pitches) > 0:
                return np.mean(pitches, axis=1)
            return np.array([])
        except Exception as e:
            logger.error(f"í”¼ì¹˜ ìœ¤ê³½ì„  ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return np.array([])

    def visualize_prosody(
        self, prosody_result: Dict[str, Any], output_path: str
    ) -> None:
        """ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        try:
            import matplotlib.pyplot as plt
            import numpy as np

            # í”¼ì¹˜ ìœ¤ê³½ì„  ë°ì´í„° ì¶”ì¶œ
            pitch_contour = prosody_result.get("pitch_contour", [])
            if len(pitch_contour) == 0:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²´í¬
                logger.warning("í”¼ì¹˜ ìœ¤ê³½ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ì‹œê°í™”
            plt.figure(figsize=(12, 6))

            # í”¼ì¹˜ ìœ¤ê³½ì„  í”Œë¡¯
            plt.subplot(2, 1, 1)
            plt.plot(pitch_contour)
            plt.title("Pitch Contour")
            plt.xlabel("Time")
            plt.ylabel("Pitch (Hz)")

            # ìŒì†Œë³„ íŠ¹ì„± í”Œë¡¯
            plt.subplot(2, 1, 2)
            phoneme_features = prosody_result.get("phoneme_features", {})
            if phoneme_features:
                durations = [f["duration"] for f in phoneme_features.values()]
                energies = [f["energy"] for f in phoneme_features.values()]
                pitches = [f["pitch"] for f in phoneme_features.values()]

                x = np.arange(len(durations))
                width = 0.25

                plt.bar(x - width, durations, width, label="Duration")
                plt.bar(x, energies, width, label="Energy")
                plt.bar(x + width, pitches, width, label="Pitch")

                plt.title("Phoneme Features")
                plt.xlabel("Phoneme")
                plt.ylabel("Value")
                plt.legend()

            plt.tight_layout()
            plt.savefig(output_path)
            plt.close()

            logger.info(f"ìš´ìœ¨ ë¶„ì„ ì‹œê°í™” ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

        except Exception as e:
            logger.error(f"ìš´ìœ¨ ë¶„ì„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def get_feedback(self, prompt: str) -> Optional[str]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            prompt: GPT í”„ë¡¬í”„íŠ¸

        Returns:
            Optional[str]: ìƒì„±ëœ í”¼ë“œë°± (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")

            if not self.openai_api_key:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            client = OpenAI(api_key=self.openai_api_key)
            response = client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ ë°œìŒ ê°•ì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìê°€ ì™¸êµ­ì¸ì„ì„ ê³ ë ¤í•˜ì—¬ ì‰¬ìš´ ë¬¸ë²• ìš©ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    },
                    {"role": "user", "content": prompt},
                ],
            )

            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def generate_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
        prosody_feedback: Optional[List[str]] = None,
    ) -> str:
        """GPT í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒì€ í•œêµ­ì–´ í•™ìŠµìì˜ ë°œí™” ì •ë³´ì™€ ì›ì–´ë¯¼ì˜ ì˜ˆì‹œ ë°œí™” ì •ë³´ì…ë‹ˆë‹¤.

# í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸:
"{learner_text}"

# ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸:
"{native_text}"

# ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸:
"{script_text}"

# í•™ìŠµìì˜ ìŒì†Œ ì •ë ¬ ì •ë³´ (MFA ë¶„ì„ ê²°ê³¼):
{learner_timing}

# ì›ì–´ë¯¼ì˜ ìŒì†Œ ì •ë ¬ ì •ë³´ (MFA ë¶„ì„ ê²°ê³¼):
{native_timing}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

1. í•™ìŠµìì™€ ì›ì–´ë¯¼ì˜ ë°œìŒ ì°¨ì´ì :
   - ì–´ë–¤ ë‹¨ì–´ë‚˜ ìŒì†Œì—ì„œ ì°¨ì´ê°€ ë‚˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
   - ì›ì–´ë¯¼ì€ ì–´ë–»ê²Œ ë°œìŒí•˜ëŠ”ì§€ í•¨ê»˜ ì„¤ëª…
   - ì˜ˆì‹œ: "í•™ìŠµìëŠ” 'ã…“'ë¥¼ 'ã…—'ì²˜ëŸ¼ ë°œìŒí–ˆëŠ”ë°, ì›ì–´ë¯¼ì€ 'ã…“'ë¥¼ ë” ë„“ê²Œ ë°œìŒí–ˆìŠµë‹ˆë‹¤."

2. í•™ìŠµìì™€ ì›ì–´ë¯¼ì˜ ë°œí™” ì†ë„ ì°¨ì´:
   - ì–´ë–¤ êµ¬ì ˆì—ì„œ ì†ë„ ì°¨ì´ê°€ ë‚˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
   - ì›ì–´ë¯¼ì˜ ë°œí™” ì†ë„ë¥¼ ì°¸ê³ í•˜ì—¬ ê°œì„  ë°©í–¥ ì œì‹œ
   - ì˜ˆì‹œ: "ì›ì–´ë¯¼ì€ 'ì•ˆë…•í•˜ì„¸ìš”'ë¥¼ 0.8ì´ˆì— ë°œìŒí–ˆëŠ”ë°, í•™ìŠµìëŠ” 1.2ì´ˆê°€ ê±¸ë ¸ìŠµë‹ˆë‹¤."

3. í•™ìŠµìì™€ ì›ì–´ë¯¼ì˜ ì–µì–‘ íŒ¨í„´ ì°¨ì´:
   - ì–´ë–¤ ë¶€ë¶„ì—ì„œ ì–µì–‘ì´ ë‹¤ë¥¸ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
   - ì›ì–´ë¯¼ì˜ ì–µì–‘ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ ê°œì„  ë°©í–¥ ì œì‹œ
   - ì˜ˆì‹œ: "ì›ì–´ë¯¼ì€ ë¬¸ì¥ ëì—ì„œ ìŒë†’ì´ê°€ ë‚´ë ¤ê°€ëŠ”ë°, í•™ìŠµìëŠ” ì˜¬ë¼ê°”ìŠµë‹ˆë‹¤."

4. êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ:
   - ì›ì–´ë¯¼ ë°œí™”ë¥¼ ì°¸ê³ í•˜ì—¬ ê° ë¬¸ì œì ë³„ ê°œì„  ë°©ë²• ì œì‹œ
   - ì‹¤ì œ ë°œìŒ ì—°ìŠµ ë°©ë²• êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
   - ì˜ˆì‹œ: "ì›ì–´ë¯¼ì²˜ëŸ¼ ë°œìŒí•˜ë ¤ë©´ ì…ì„ ë” í¬ê²Œ ë²Œë¦¬ê³  'ã…“'ë¥¼ ë°œìŒí•´ë³´ì„¸ìš”."

5. ì—°ìŠµ ì „ëµ:
   - ì›ì–´ë¯¼ ë°œí™”ë¥¼ ë”°ë¼í•˜ëŠ” êµ¬ì²´ì ì¸ ë°©ë²• ì œì‹œ
   - ì–´ë–¤ ë¶€ë¶„ë¶€í„° ì—°ìŠµí•˜ë©´ ì¢‹ì„ì§€ ìˆœì„œëŒ€ë¡œ ì„¤ëª…
   - ì˜ˆì‹œ: "ë¨¼ì € 'ì•ˆë…•í•˜ì„¸ìš”'ì˜ 'ë…•' ë¶€ë¶„ì„ ì²œì²œíˆ ì—°ìŠµí•œ í›„, ì „ì²´ ë¬¸ì¥ì„ ì—°ìŠµí•˜ì„¸ìš”."
"""

        # RAGê°€ í™œì„±í™”ëœ ê²½ìš°, ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ ë° ì¶”ê°€
        if self.config["use_rag"] and self.knowledge_base:
            # ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ
            issues = self.extract_pronunciation_issues(
                learner_text, native_text, learner_timing, native_timing
            )

            # ì¿¼ë¦¬ ìƒì„±
            query = f"í•œêµ­ì–´ ë°œìŒ: {' '.join([issue['type'] for issue in issues])}"

            # ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
            relevant_docs = self.knowledge_base.search(query, top_k=3)

            if relevant_docs:
                prompt += "\n\n# ì°¸ê³ í•  ë°œìŒ ì§€ì‹:\n"
                for doc in relevant_docs:
                    prompt += f"- {doc['content']}\n"

                prompt += "\nìœ„ ì°¸ê³  ì§€ì‹ì„ í™œìš©í•˜ì—¬ í•™ìŠµìì—ê²Œ ë” êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”."

        # ì–µì–‘/ê°•ì„¸ í”¼ë“œë°± ì¶”ê°€
        if prosody_feedback:
            prompt += "\n\n# ì–µì–‘ê³¼ ê°•ì„¸ ë¶„ì„ ê²°ê³¼:\n"
            for feedback in prosody_feedback:
                prompt += f"- {feedback}\n"

            prompt += "\nìœ„ ì–µì–‘ê³¼ ê°•ì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬, ì›ì–´ë¯¼ ë°œí™”ì™€ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."

        return prompt

    def extract_pronunciation_issues(
        self,
        learner_result: Dict,
        reference_result: Dict,
        learner_timing: Dict,
        reference_timing: Dict
    ) -> List[Dict]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ

        Args:
            learner_result: í•™ìŠµì ì¸ì‹ ê²°ê³¼
            reference_result: ì›ì–´ë¯¼ ì¸ì‹ ê²°ê³¼
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´
            reference_timing: ì›ì–´ë¯¼ íƒ€ì´ë° ì •ë³´

        Returns:
            List[Dict]: ë°œìŒ ë¬¸ì œì  ëª©ë¡
        """
        issues = []
        
        # ë‹¨ì–´ ë‹¨ìœ„ ë¹„êµ (ì•ˆì „í•œ ì ‘ê·¼)
        learner_words = learner_result.get("words", [])
        reference_words = reference_result.get("words", [])
        
        if learner_words and reference_words:
            # ìµœì†Œ ê¸¸ì´ë§Œí¼ ë¹„êµ
            min_length = min(len(learner_words), len(reference_words))
            for i in range(min_length):
                learner_word = learner_words[i]
                ref_word = reference_words[i]
                
                # ë‹¨ì–´ ê°ì²´ê°€ ë”•ì…”ë„ˆë¦¬ì´ê³  'word' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if (isinstance(learner_word, dict) and 'word' in learner_word and 
                    isinstance(ref_word, dict) and 'word' in ref_word):
                    
                    if learner_word["word"] != ref_word["word"]:
                        issues.append({
                            "type": "word_mismatch",
                            "position": i,
                            "learner": learner_word["word"],
                            "reference": ref_word["word"],
                            "start": learner_word.get("start", 0),
                            "end": learner_word.get("end", 0)
                        })
        
        # í…ìŠ¤íŠ¸ ë ˆë²¨ì—ì„œì˜ ê¸°ë³¸ ë¹„êµ (ë‹¨ì–´ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°)
        if not learner_words or not reference_words:
            learner_text = learner_result.get("text", "").strip()
            reference_text = reference_result.get("text", "").strip()
            
            if learner_text != reference_text:
                issues.append({
                    "type": "text_mismatch", 
                    "learner": learner_text,
                    "reference": reference_text
                })
        
        # ìš´ìœ¨ ë¹„êµ
        if "prosody" in learner_result and "prosody" in reference_result:
            learner_prosody = learner_result["prosody"]
            reference_prosody = reference_result["prosody"]
            
            # í”¼ì¹˜ ì°¨ì´
            if ("pitch" in learner_prosody and "pitch" in reference_prosody and
                "mean" in learner_prosody["pitch"] and "mean" in reference_prosody["pitch"]):
                
                pitch_diff = abs(learner_prosody["pitch"]["mean"] - reference_prosody["pitch"]["mean"])
                if pitch_diff > 20:  # 20Hz ì´ìƒ ì°¨ì´ë‚˜ë©´ ë¬¸ì œë¡œ íŒë‹¨
                    issues.append({
                        "type": "pitch_difference",
                        "learner_mean": learner_prosody["pitch"]["mean"],
                        "reference_mean": reference_prosody["pitch"]["mean"],
                        "difference": pitch_diff
                    })
            
            # ì—ë„ˆì§€ ì°¨ì´
            if ("energy" in learner_prosody and "energy" in reference_prosody and
                "mean" in learner_prosody["energy"] and "mean" in reference_prosody["energy"]):
                
                energy_diff = abs(learner_prosody["energy"]["mean"] - reference_prosody["energy"]["mean"])
                if energy_diff > 0.1:  # 0.1 ì´ìƒ ì°¨ì´ë‚˜ë©´ ë¬¸ì œë¡œ íŒë‹¨
                    issues.append({
                        "type": "energy_difference",
                        "learner_mean": learner_prosody["energy"]["mean"],
                        "reference_mean": reference_prosody["energy"]["mean"],
                        "difference": energy_diff
                    })
        
        return issues

    def align_audio(self, audio_path: str, text: str, speaker_type: str) -> Optional[Dict]:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            text: ì •ë ¬í•  í…ìŠ¤íŠ¸
            speaker_type: í™”ì íƒ€ì… ("learner" ë˜ëŠ” "native")

        Returns:
            Optional[Dict]: ì •ë ¬ ê²°ê³¼
        """
        try:
            # MFA ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
            mfa_input_dir = self.temp_dir / "mfa_input" / speaker_type
            mfa_input_dir.mkdir(parents=True, exist_ok=True)
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ì„ mfa_input ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            audio_filename = Path(audio_path).name
            shutil.copy2(audio_path, mfa_input_dir / audio_filename)
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            text_filename = Path(audio_path).stem + ".txt"
            with open(mfa_input_dir / text_filename, "w", encoding="utf-8") as f:
                f.write(text)

            # MFA ì •ë ¬ ì‹¤í–‰
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {speaker_type}")
            command = [
                "mfa",
                "align",
                str(mfa_input_dir),
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output / speaker_type),
                "--clean",
            ]
            subprocess.run(command, check=True)
            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")

            # TextGrid íŒŒì¼ ì½ê¸°
            textgrid_path = self.mfa_output / speaker_type / f"{Path(audio_path).stem}.TextGrid"
            if not textgrid_path.exists():
                logger.error(f"TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {textgrid_path}")
                return None

            # TextGrid íŒŒì‹±
            with open(textgrid_path, "r", encoding="utf-8") as f:
                textgrid_content = f.read()

            # ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë° ì •ë³´ ì¶”ì¶œ
            timing_info = {}
            current_word = None
            for line in textgrid_content.split("\n"):
                if line.strip().startswith('text = "'):
                    current_word = line.strip()[8:-1]  # "text = " ì œê±°
                elif line.strip().startswith('xmin = '):
                    start_time = float(line.strip()[7:])
                elif line.strip().startswith('xmax = '):
                    end_time = float(line.strip()[7:])
                    if current_word:
                        timing_info[current_word] = {
                            "start": start_time,
                            "end": end_time
                        }

            return timing_info

        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def convert_audio(self, audio_path: str) -> Optional[str]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ (.m4a -> .wav)

        Args:
            audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ë³€í™˜ëœ wav íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì…ë ¥ íŒŒì¼ ê²½ë¡œ í™•ì¸
            input_path = Path(audio_path)
            if not input_path.exists():
                logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
                return None

            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            output_dir = self.temp_dir / "wav"
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"{input_path.stem}.wav"

            # ffmpegë¡œ ë³€í™˜
            subprocess.run([
                "ffmpeg",
                "-i", str(input_path),
                "-acodec", "pcm_s16le",
                "-ar", "16000",
                "-ac", "1",
                "-y",  # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
                str(output_path)
            ], check=True)

            logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            return str(output_path)

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def _generate_simple_feedback(self, result: Dict) -> Optional[Dict]:
        """ê°„ë‹¨í•œ í”¼ë“œë°± ìƒì„±
        
        Args:
            result: ë¶„ì„ ê²°ê³¼
            
        Returns:
            Optional[Dict]: í”¼ë“œë°± ê²°ê³¼
        """
        try:
            feedback = {
                "summary": "ë°œìŒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "suggestions": []
            }
            
            # ë°œìŒ ë¬¸ì œì ì´ ìˆë‹¤ë©´ í”¼ë“œë°± ì¶”ê°€
            if "issues" in result["comparison"]:
                issues = result["comparison"]["issues"]
                if issues:
                    feedback["suggestions"].append("ë°œê²¬ëœ ë°œìŒ ë¬¸ì œì ë“¤ì„ ê°œì„ í•´ë³´ì„¸ìš”.")
                    for issue in issues[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                        if issue["type"] == "word_mismatch":
                            feedback["suggestions"].append(
                                f"'{issue['learner']}'ì„(ë¥¼) '{issue['reference']}'ë¡œ ë°œìŒí•´ë³´ì„¸ìš”."
                            )
                        elif issue["type"] == "text_mismatch":
                            feedback["suggestions"].append(
                                "ë°œìŒëœ í…ìŠ¤íŠ¸ì™€ ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ë‹¤ë¦…ë‹ˆë‹¤."
                            )
            
            # ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ í”¼ë“œë°± ì¶”ê°€
            if "prosody" in result["comparison"]:
                prosody = result["comparison"]["prosody"]
                if prosody:
                    feedback["suggestions"].append("ì–µì–‘ê³¼ ê°•ì„¸ë¥¼ ì›ì–´ë¯¼ê³¼ ë¹„êµí•˜ì—¬ ê°œì„ í•´ë³´ì„¸ìš”.")
            
            return feedback
            
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def summarize_textgrid(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ ìŒì†Œ ì •ë³´ ì¶”ì¶œ

        Args:
            path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ìŒì†Œ ì •ë³´ ìš”ì•½ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
            import textgrid
            tg = textgrid.TextGrid.fromFile(path)
            summary = []

            for tier in tg.tiers:
                if tier.name.lower() in ["phones", "phoneme", "phone"]:
                    for interval in tier:
                        if interval.mark.strip():
                            summary.append(
                                f"{interval.mark}: {round(interval.minTime, 2)}s ~ {round(interval.maxTime, 2)}s"
                            )

            return "\n".join(summary)
        except Exception as e:
            logger.error(f"TextGrid ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def summarize_textgrid_compact(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ í•µì‹¬ ìŒì†Œ ì •ë³´ë§Œ ì¶”ì¶œ (ì••ì¶• ë²„ì „)

        Args:
            path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ì••ì¶•ëœ ìŒì†Œ ì •ë³´ ìš”ì•½
        """
        try:
            logger.info(f"ğŸ“Š TextGrid ì••ì¶• ìš”ì•½ ì¤‘: {path}")
            import textgrid
            tg = textgrid.TextGrid.fromFile(path)
            
            # ì¤‘ìš”í•œ ìŒì†Œë§Œ í•„í„°ë§ (ë¬´ìŒ êµ¬ê°„ ì œì™¸)
            important_phonemes = []
            
            for tier in tg.tiers:
                if tier.name.lower() in ["phones", "phoneme", "phone"]:
                    for interval in tier:
                        phoneme = interval.mark.strip()
                        # ë¬´ìŒ êµ¬ê°„ì´ë‚˜ ì¹¨ë¬µ êµ¬ê°„ ì œì™¸
                        if phoneme and phoneme not in ['', 'sil', 'sp', '<eps>']:
                            duration = round(interval.maxTime - interval.minTime, 2)
                            # 0.05ì´ˆ ì´ìƒì¸ ìŒì†Œë§Œ í¬í•¨ (ë„ˆë¬´ ì§§ì€ ê²ƒë“¤ ì œì™¸)
                            if duration >= 0.05:
                                important_phonemes.append(f"{phoneme}({duration}s)")
            
            # ìµœëŒ€ 20ê°œì˜ í•µì‹¬ ìŒì†Œë§Œ ë°˜í™˜
            if len(important_phonemes) > 20:
                # ì•ìª½ 10ê°œ, ë’¤ìª½ 10ê°œë§Œ ì„ íƒ
                important_phonemes = important_phonemes[:10] + ['...'] + important_phonemes[-10:]
            
            return ", ".join(important_phonemes)
            
        except Exception as e:
            logger.error(f"TextGrid ì••ì¶• ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def extract_pronunciation_issues_detailed(
        self, learner_text: str, native_text: str, learner_timing: str
    ) -> List[str]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ (ìƒì„¸ ë¶„ì„)

        Args:
            learner_text: í•™ìŠµì í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ í…ìŠ¤íŠ¸
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´

        Returns:
            List[str]: ë°œê²¬ëœ ë¬¸ì œì  ëª©ë¡
        """
        issues = []

        # 1. í…ìŠ¤íŠ¸ ê¸¸ì´ ì°¨ì´ (ë„ˆë¬´ í¬ë©´ ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„±)
        if len(native_text) > len(learner_text) * 1.2:
            issues.append("ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„± ìˆìŒ")

        # 2. ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
        learner_words = learner_text.split()
        native_words = native_text.split()

        for n_word in native_words:
            if len(n_word) >= 2 and n_word not in learner_text:
                # ë°›ì¹¨ì´ ìˆëŠ” ë‹¨ì–´ë©´ ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê°€ëŠ¥ì„± ì¶”ê°€
                if any(c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…" for c in n_word):
                    issues.append(f"'{n_word}' ë‹¨ì–´ ë°œìŒ ë¬¸ì œ (ë°›ì¹¨ ê´€ë ¨)")

        # 3. ê³µí†µ ìŒì†Œ ë¬¸ì œ (ìŒì†Œ ê¸¸ì´, ìŒìƒ‰ ë“±)
        phoneme_issues = set()
        for line in learner_timing.split(","):
            parts = line.split("(")
            if len(parts) >= 2:
                phoneme = parts[0].strip()

                # ëª¨ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã…“", "ã…—", "ã…œ", "ã…¡"]:
                    phoneme_issues.add(f"{phoneme} ëª¨ìŒ ë°œìŒ")

                # ê²½ìŒ/ê²©ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã„²", "ã„¸", "ã…ƒ", "ã…†", "ã…‰", "ã…‹", "ã…Œ", "ã…", "ã…Š"]:
                    phoneme_issues.add(f"{phoneme} ììŒ ë°œìŒ")

        issues.extend(list(phoneme_issues))
        return issues

    def generate_detailed_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
        prosody_feedback: Optional[Dict] = None,
    ) -> str:
        """ìƒì„¸í•œ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            learner_text: í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸
            script_text: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸
            learner_timing: í•™ìŠµì ìŒì†Œ ì •ë ¬ ì •ë³´
            native_timing: ì›ì–´ë¯¼ ìŒì†Œ ì •ë ¬ ì •ë³´
            prosody_feedback: ìš´ìœ¨ ë¶„ì„ ê²°ê³¼

        Returns:
            str: GPT í”„ë¡¬í”„íŠ¸
        """
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒì€ í•œêµ­ì–´ í•™ìŠµìì˜ ë°œí™” ì •ë³´ì™€ ì›ì–´ë¯¼ì˜ ì˜ˆì‹œ ë°œí™” ì •ë³´ì…ë‹ˆë‹¤.

# í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸:
"{learner_text}"

# ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸:
"{native_text}"

# ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸:
"{script_text}"

# í•™ìŠµìì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{learner_timing}

# ì›ì–´ë¯¼ì˜ ìŒì†Œ ì •ë ¬ ì •ë³´:
{native_timing}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

1. í•™ìŠµìì˜ ë°œìŒì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ë¶€ì •í™•í•œ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?
   - êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ

2. í•™ìŠµìì˜ ë°œìŒì—ì„œ ë¶€ì ì ˆí•˜ê²Œ ë„ì–´ ì½ì€ ë‹¨ì–´ë‚˜ ìŒì†ŒëŠ” ë¬´ì—‡ì¸ê°€?  
   - ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

3. ì›ì–´ë¯¼ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ **ë‹¨ì–´ë‚˜ êµ¬ì ˆì—ì„œ** ì†ë„ ì°¨ì´ê°€ ìˆëŠ”ê°€?  
   - ì†ë„ ì •ë³´ë¥¼ ì œì‹œí•  ë•ŒëŠ” ê¼­ í•´ë‹¹í•˜ëŠ” **ë‹¨ì–´ë‚˜ ìŒì†Œ**ë¥¼ í•¨ê»˜ ì œì‹œ

4. ë” ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•˜ê¸° ìœ„í•œ íŒì„ ê°„ë‹¨íˆ ì œì‹œ
"""

        # ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if prosody_feedback:
            prompt += f"\n\n# ìš´ìœ¨ ë° ì–µì–‘ ë¶„ì„ ê²°ê³¼:\n"
            if 'differences' in prosody_feedback:
                diff = prosody_feedback['differences']
                prompt += f"- í”¼ì¹˜ í‰ê·  ì°¨ì´: {diff.get('pitch', {}).get('mean', 0):.2f}Hz\n"
                prompt += f"- ì—ë„ˆì§€ í‰ê·  ì°¨ì´: {diff.get('energy', {}).get('mean', 0):.3f}\n"
                prompt += f"- ë§í•˜ê¸° ì†ë„ ì°¨ì´: {diff.get('time', {}).get('total_duration', 0):.2f}ì´ˆ\n"
            
            prompt += "\nìœ„ ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ í•™ìŠµìì˜ ì–µì–‘ê³¼ ê°•ì„¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ë„ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”."

        # RAGê°€ í™œì„±í™”ëœ ê²½ìš°, ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ ë° ì¶”ê°€
        if self.config["use_rag"] and self.knowledge_base:
            # ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ
            issues = self.extract_pronunciation_issues_detailed(
                learner_text, native_text, learner_timing
            )

            # ì¿¼ë¦¬ ìƒì„±
            query = f"í•œêµ­ì–´ ë°œìŒ: {' '.join(issues)}"

            # ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
            relevant_docs = self.knowledge_base.search(query, top_k=3)

            if relevant_docs:
                prompt += "\n\n# ì°¸ê³ í•  ë°œìŒ ì§€ì‹:\n"
                for doc in relevant_docs:
                    prompt += f"- {doc['content']}\n"

                prompt += "\nìœ„ ì°¸ê³  ì§€ì‹ì„ í™œìš©í•˜ì—¬ í•™ìŠµìì—ê²Œ ë” êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”."

        return prompt

    def generate_compact_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
        prosody_feedback: Optional[Dict] = None,
    ) -> str:
        """ì••ì¶•ëœ GPT í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ì ˆì•½í˜•)

        Args:
            learner_text: í•™ìŠµì ë°œí™” í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ ë°œí™” í…ìŠ¤íŠ¸
            script_text: ëª©í‘œ ìŠ¤í¬ë¦½íŠ¸
            learner_timing: í•™ìŠµì ìŒì†Œ ì •ë ¬ ì •ë³´ (ì••ì¶•í˜•)
            native_timing: ì›ì–´ë¯¼ ìŒì†Œ ì •ë ¬ ì •ë³´ (ì••ì¶•í˜•)
            prosody_feedback: ìš´ìœ¨ ë¶„ì„ ê²°ê³¼

        Returns:
            str: ì••ì¶•ëœ GPT í”„ë¡¬í”„íŠ¸
        """
        
        # ê¸°ë³¸ ì •ë³´ë§Œ í¬í•¨í•œ ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""í•œêµ­ì–´ ë°œìŒ êµì • ìš”ì²­:

í•™ìŠµì: "{learner_text}"
ì›ì–´ë¯¼: "{native_text}"
ëª©í‘œ: "{script_text}"

í•µì‹¬ ìŒì†Œ ì •ë³´:
- í•™ìŠµì: {learner_timing}
- ì›ì–´ë¯¼: {native_timing}

ë¶„ì„ ìš”ì²­:
1. ì˜ëª» ë°œìŒëœ ë‹¨ì–´/ìŒì†Œ
2. ëˆ„ë½ëœ ë¶€ë¶„  
3. ì†ë„ ë¬¸ì œ
4. ê°œì„  ë°©ë²•

ê°„ê²°í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # ìš´ìœ¨ ì •ë³´ ì¶”ê°€ (ì••ì¶•í˜•)
        if prosody_feedback and 'differences' in prosody_feedback:
            diff = prosody_feedback['differences']
            pitch_diff = diff.get('pitch', {}).get('mean', 0)
            energy_diff = diff.get('energy', {}).get('mean', 0)
            if abs(pitch_diff) > 20 or abs(energy_diff) > 0.1:
                prompt += f"\n\nìš´ìœ¨ ì°¨ì´: í”¼ì¹˜{pitch_diff:+.0f}Hz, ì—ë„ˆì§€{energy_diff:+.2f}"

        # RAG ì§€ì‹ (ìµœëŒ€ 1ê°œë§Œ)
        if self.config["use_rag"] and self.knowledge_base:
            issues = self.extract_pronunciation_issues_detailed(
                learner_text, native_text, learner_timing
            )
            if issues:
                query = f"í•œêµ­ì–´ ë°œìŒ: {issues[0]}"  # ì²« ë²ˆì§¸ ì´ìŠˆë§Œ ì‚¬ìš©
                relevant_docs = self.knowledge_base.search(query, top_k=1)
                if relevant_docs:
                    prompt += f"\n\nì°¸ê³ : {relevant_docs[0]['content'][:200]}..."  # 200ìë§Œ ì‚¬ìš©

        return prompt
