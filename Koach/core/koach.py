import os
import logging
import json
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List
import shutil
import subprocess
import librosa
import textgrid
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import faiss
from dotenv import load_dotenv
from datetime import datetime

from utils.audio import (
    convert_audio,
    transcribe_audio,
    extract_audio_segment,
    normalize_audio,
    get_audio_duration,
    get_audio_info,
)
from utils.text import (
    summarize_textgrid,
    extract_word_boundaries,
    align_text_with_audio,
    extract_phoneme_features,
    compare_phoneme_sequences,
)
from core.prosody import ProsodyAnalyzer
from core.knowledge_base import KnowledgeBase
from config.settings import CURRENT_CONFIG, PATHS, OUTPUT_DIR, TEMP_ROOT, VISUALIZE_DIR

logger = logging.getLogger(__name__)


class Koach:
    """í•œêµ­ì–´ ë°œìŒ êµì • ë„ìš°ë¯¸"""

    def __init__(self, config: Optional[Dict] = None):
        """ì´ˆê¸°í™”

        Args:
            config: ì‚¬ìš©ì ì„¤ì •
        """
        # ìƒìœ„ í´ë”ì˜ .env íŒŒì¼ ë¡œë“œ
        env_path = Path(__file__).parent.parent.parent / '.env'
        load_dotenv(env_path)
        
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            logger.warning("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = OUTPUT_DIR

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.temp_dir = TEMP_ROOT
        self.temp_dir.mkdir(exist_ok=True)

        # ë² íƒ€ ë²„ì „ì˜ ì„¤ì • êµ¬ì¡° í†µí•©
        self.config = {
            # Whisper ëª¨ë¸ ì„¤ì •
            "whisper_model": "base",
            "language": "ko",
            # OpenAI ëª¨ë¸ (ë² íƒ€ì—ì„œ ê°œì„ ëœ ëª¨ë¸)
            "openai_model": "gpt-4o",
            # RAG ì„¤ì •
            "use_rag": True,
            "knowledge_dir": "knowledge",
            "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
        }

        # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if config:
            self.config.update(config)

        # íŒŒì¼ ê²½ë¡œ ì„¤ì • (settings.pyì˜ PATHS ì‚¬ìš©)
        self.learner_audio = PATHS["learner_audio"]
        self.native_audio = PATHS["native_audio"]
        self.learner_wav = PATHS["learner_wav"]
        self.native_wav = PATHS["native_wav"]
        self.learner_transcript = PATHS["learner_transcript"]
        self.native_transcript = PATHS["native_transcript"]
        self.script_path = PATHS["script_path"]
        self.learner_textgrid = PATHS["learner_textgrid"]
        self.native_textgrid = PATHS["native_textgrid"]
        self.lexicon_path = PATHS["lexicon_path"]
        self.acoustic_model = PATHS["acoustic_model"]
        self.mfa_input = PATHS["mfa_input"]
        self.mfa_output = PATHS["mfa_output"]

        # RAG ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì„¤ì •ì— ë”°ë¼)
        if self.config["use_rag"]:
            self.knowledge_base = KnowledgeBase(
                knowledge_dir=self.config["knowledge_dir"],
                embedding_model=self.config["embedding_model"],
            )
        else:
            self.knowledge_base = None

        self.model_name = "base"
        self.prosody_analyzer = ProsodyAnalyzer()

        # ì‹œê°í™” ë””ë ‰í† ë¦¬ ì„¤ì •
        self.visualize_dir = VISUALIZE_DIR

    def analyze_pronunciation(
        self,
        learner_audio: Optional[str] = None,
        native_audio: Optional[str] = None,
        script: Optional[str] = None,
        visualize: bool = True,
    ) -> Dict:
        """ë°œìŒ ë¶„ì„ ì‹¤í–‰"""
        try:
            result = {
                "steps": {},
                "errors": [],
                "status": "ì§„í–‰ì¤‘",
            }

            # 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
            if not learner_audio:
                learner_audio = str(self.learner_audio)
            if not native_audio:
                native_audio = str(self.native_audio)

            # ğŸ“ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìë™ ë¡œë“œ ì²˜ë¦¬
            script_text = None
            if script:
                script_config = CURRENT_CONFIG["script"]
                
                if script_config["auto_detect_file"] and (
                    any(script.endswith(ext) for ext in script_config["supported_extensions"]) or 
                    '/' in script or '\\' in script
                ):
                    # íŒŒì¼ ê²½ë¡œë¡œ íŒë‹¨
                    try:
                        script_path = Path(script)
                        if script_path.exists():
                            # íŒŒì¼ í¬ê¸° í™•ì¸
                            if script_path.stat().st_size > script_config["max_file_size"]:
                                logger.warning(f"âš ï¸ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {script_path}")
                                script_text = script
                            else:
                                with open(script_path, 'r', encoding=script_config["encoding"]) as f:
                                    script_text = f.read().strip()
                                logger.info(f"ğŸ“„ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë¡œë“œë¨: {script_path}")
                                logger.info(f"ğŸ“ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©: {script_text[:50]}...")
                        else:
                            logger.warning(f"âš ï¸ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {script_path}")
                            script_text = script  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                    except Exception as e:
                        logger.error(f"âŒ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                        script_text = script  # ì—ëŸ¬ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                else:
                    # ì§ì ‘ í…ìŠ¤íŠ¸ë¡œ íŒë‹¨
                    script_text = script
                    logger.info(f"ğŸ“ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥: {script_text[:50]}...")
                
                result["script_text"] = script_text

            # 2. ì˜¤ë””ì˜¤ ë³€í™˜ ë° ì •ê·œí™”
            logger.info("ğŸ¯ 1ë‹¨ê³„: ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ ë° ì •ê·œí™”")
            
            # WAV ë³€í™˜
            convert_audio(learner_audio, str(self.learner_wav))
            convert_audio(native_audio, str(self.native_wav))
            
            # ì •ê·œí™” ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            learner_normalized = self.get_normalized_paths("learner")["normalized"]
            native_normalized = self.get_normalized_paths("native")["normalized"]
            
            # ì •ê·œí™” ì‹œë„
            if not normalize_audio(self.learner_wav, learner_normalized):
                logger.warning("í•™ìŠµì ì˜¤ë””ì˜¤ ì •ê·œí™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")
                learner_normalized = self.learner_wav
            
            if not normalize_audio(self.native_wav, native_normalized):
                logger.warning("ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ ì •ê·œí™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")
                native_normalized = self.native_wav

            result["steps"]["audio_conversion"] = "ì„±ê³µ"

            # 3. ìŒì„± ì¸ì‹ (ìŠ¤í¬ë¦½íŠ¸ ì œê³µ ì‹œì—ë„ ì „ì‚¬ ì‹¤í–‰)
            logger.info("ğŸ¯ 2ë‹¨ê³„: ìŒì„± ì¸ì‹")
            
            # ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆì–´ë„ ì‹¤ì œ ë°œí™” ë‚´ìš© í™•ì¸ì„ ìœ„í•´ ì „ì‚¬ ì‹¤í–‰
            learner_result = transcribe_audio(learner_normalized)
            native_result = transcribe_audio(native_normalized)
            
            if not learner_result or not native_result:
                if script_text:
                    # ì „ì‚¬ ì‹¤íŒ¨ ì‹œì—ë§Œ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
                    logger.warning("âš ï¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨, ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©")
                    result["learner_text"] = script_text
                    result["native_text"] = script_text
                    result["steps"]["speech_recognition"] = "ì‹¤íŒ¨(ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©)"
                else:
                    raise Exception("ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            else:
                result["learner_text"] = learner_result.get("text", "")
                result["native_text"] = native_result.get("text", "")
                result["steps"]["speech_recognition"] = "ì„±ê³µ"
                
                # ìŠ¤í¬ë¦½íŠ¸ì™€ ì‹¤ì œ ë°œí™” ë¹„êµ ë¡œê·¸
                if script_text:
                    logger.info(f"ğŸ“‹ ëª©í‘œ: {script_text}")
                    logger.info(f"ğŸ¤ ì‹¤ì œ: {result['learner_text']}")

            # 4. ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì €ì¥
            if script_text:
                with open(self.script_path, "w", encoding="utf-8") as f:
                    f.write(script_text)

            # 5. MFA ì •ë ¬ (ìµœì í™” ë° ê±´ë„ˆë›°ê¸° ì˜µì…˜) - ë°©ë²• 3
            logger.info("ğŸ¯ 3ë‹¨ê³„: MFA ì •ë ¬")
            
            # Whisper ì „ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            with open(self.learner_transcript, "w", encoding="utf-8") as f:
                f.write(result["learner_text"])
            with open(self.native_transcript, "w", encoding="utf-8") as f:
                f.write(result["native_text"])
            
            # MFA ê±´ë„ˆë›°ê¸° ì˜µì…˜ í™•ì¸
            if CURRENT_CONFIG["mfa"].get("skip_mfa", False):
                logger.info("âš¡ MFA ì •ë ¬ ê±´ë„ˆë›°ê¸° (ì„¤ì •)")
                result["steps"]["mfa_alignment"] = "ê±´ë„ˆëœ€"
                learner_timing = ""
                native_timing = ""
            else:
                # ë°°ì¹˜ ì •ë ¬ ì‹œë„ (ë°©ë²• 1)
                alignment_success = False
                
                if CURRENT_CONFIG["mfa"].get("batch_processing", True):
                    try:
                        logger.info("ğŸš€ ë°°ì¹˜ ì •ë ¬ ëª¨ë“œ ì‹œë„...")
                        alignment_success = self.run_mfa_alignment_batch(
                            learner_normalized, native_normalized,
                            self.learner_transcript, self.native_transcript
                        )
                    except Exception as e:
                        logger.warning(f"ë°°ì¹˜ ì •ë ¬ ì‹¤íŒ¨: {e}")
                
                # ë°°ì¹˜ ì •ë ¬ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë°±ì—…
                if not alignment_success:
                    logger.info("ğŸ”„ ê¸°ì¡´ ì •ë ¬ ë°©ì‹ìœ¼ë¡œ ë°±ì—…...")
                    try:
                        learner_aligned = self.run_mfa_alignment_legacy(
                            learner_normalized, self.learner_transcript, "learner"
                        )
                        native_aligned = self.run_mfa_alignment_legacy(
                            native_normalized, self.native_transcript, "native"
                        )
                        alignment_success = learner_aligned and native_aligned
                    except Exception as e:
                        logger.warning(f"ê¸°ì¡´ ì •ë ¬ë„ ì‹¤íŒ¨: {e}")
                        alignment_success = False

                # ê²°ê³¼ ì²˜ë¦¬
                if alignment_success:
                    result["steps"]["mfa_alignment"] = "ì„±ê³µ"
                    # ì••ì¶•ëœ TextGrid ìš”ì•½
                    learner_timing = self.summarize_textgrid_compact(self.learner_textgrid) or ""
                    native_timing = self.summarize_textgrid_compact(self.native_textgrid) or ""
                else:
                    logger.warning("MFA ì •ë ¬ ì™„ì „ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ì§„í–‰")
                    result["steps"]["mfa_alignment"] = "ì‹¤íŒ¨"
                    learner_timing = ""
                    native_timing = ""

            result["learner_timing"] = learner_timing
            result["native_timing"] = native_timing

            # 6. ë°œìŒ ë¶„ì„ (4ë‹¨ê³„)
            logger.info("ğŸ¯ 4ë‹¨ê³„: ë°œìŒ ë¶„ì„")
            try:
                # ìŒì†Œ ë¶„ì„
                phoneme_analysis = {}
                prosody_analysis = {}
                comparison = {}
                
                if alignment_success:
                    # ìŒì†Œ ë¶„ì„
                    phoneme_analysis = self._analyze_phonemes(
                        str(self.learner_textgrid)
                    ) or {}
                    
                    # ìš´ìœ¨ ë¶„ì„
                    prosody_analysis = self._analyze_prosody_detailed(
                        learner_normalized
                    ) or {}
                    
                    # ë¹„êµ ë¶„ì„ (ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ê°€ ìˆëŠ” ê²½ìš°)
                    if native_normalized and Path(native_normalized).exists():
                        comparison = self._compare_with_reference(
                            learner_normalized,
                            native_normalized,
                            str(self.learner_textgrid)
                        ) or {}
                
                # ê¸°ì¡´ ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ ë¡œì§ ìœ ì§€
                pronunciation_issues = self.extract_pronunciation_issues_detailed(
                    result["learner_text"], result["native_text"], learner_timing
                )
                
                # ê²°ê³¼ì— ì¶”ê°€
                result["pronunciation_issues"] = pronunciation_issues
                result["phoneme_analysis"] = phoneme_analysis
                result["prosody_analysis"] = prosody_analysis
                result["comparison"] = comparison
                result["steps"]["pronunciation_analysis"] = "ì„±ê³µ"
                
                logger.info("âœ… ë°œìŒ ë¶„ì„ ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"ë°œìŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
                result["steps"]["pronunciation_analysis"] = "ì‹¤íŒ¨"
                result["errors"].append(f"ë°œìŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
                phoneme_analysis = {}
                prosody_analysis = {}
                comparison = {}

            # ë¶„ì„ ê²°ê³¼ì—ì„œ numpy íƒ€ì… ë³€í™˜
            if "phoneme_analysis" in result:
                result["phoneme_analysis"] = self._convert_numpy_types(result["phoneme_analysis"])
            
            if "prosody_analysis" in result:
                result["prosody_analysis"] = self._convert_numpy_types(result["prosody_analysis"])
            
            if "comparison" in result:
                result["comparison"] = self._convert_numpy_types(result["comparison"])

            # 7. GPT í”¼ë“œë°± ìƒì„± (5ë‹¨ê³„)
            logger.info("ğŸ¯ 5ë‹¨ê³„: GPT í”¼ë“œë°± ìƒì„±")
            
            prompt = self.generate_compact_prompt(
                result["learner_text"], result["native_text"], script_text or "ì•Œ ìˆ˜ ì—†ìŒ",
                learner_timing, native_timing
            )
            
            gpt_feedback = self.get_feedback(prompt)
            result["feedback"] = gpt_feedback
            result["prompt_used"] = prompt

            if gpt_feedback:
                result["steps"]["gpt_feedback"] = "ì„±ê³µ"
            else:
                result["steps"]["gpt_feedback"] = "ì‹¤íŒ¨"

            # 8. ì‹œê°í™” ìƒì„± (6ë‹¨ê³„)
            if visualize and CURRENT_CONFIG["visualization"]["enabled"]:
                logger.info("ğŸ¯ 6ë‹¨ê³„: ì‹œê°í™” ìƒì„±")
                try:
                    if alignment_success:
                        visualization_paths = self._visualize_results(
                            learner_audio=learner_normalized,
                            reference_audio=native_normalized,
                            learner_textgrid=str(self.learner_textgrid),
                            phoneme_analysis=phoneme_analysis,
                            prosody_analysis=prosody_analysis,
                            comparison=comparison
                        )
                        result["visualization_paths"] = visualization_paths
                        result["steps"]["visualization"] = "ì„±ê³µ"
                        logger.info(f"âœ… ì‹œê°í™” ì™„ë£Œ: {len(visualization_paths)}ê°œ íŒŒì¼ ìƒì„±")
                    else:
                        logger.warning("âš ï¸ MFA ì •ë ¬ ì‹¤íŒ¨ë¡œ ì‹œê°í™” ê±´ë„ˆë›°ê¸°")
                        result["steps"]["visualization"] = "ê±´ë„ˆëœ€"
                except Exception as e:
                    logger.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
                    result["steps"]["visualization"] = "ì‹¤íŒ¨"
                    result["errors"].append(f"ì‹œê°í™” ì˜¤ë¥˜: {str(e)}")
            
            result["status"] = "ì™„ë£Œ"
            logger.info("ğŸ‰ ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
            return result

        except Exception as e:
            logger.error(f"ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜: {e}")
            result["errors"].append(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}")
            result["status"] = "ì‹¤íŒ¨"
            return result

    def run_mfa_alignment(
        self, wav_path: str, transcript_path: str, output_name: str
    ) -> bool:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬"""
        try:
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {output_name}")

            # MFA ì…ë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
            mfa_input_dir = self.mfa_input / output_name
            mfa_input_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ë³µì‚¬ (ê²½ë¡œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ)
            target_wav = str(mfa_input_dir / f"{output_name}.wav")
            target_txt = str(mfa_input_dir / f"{output_name}.txt")

            if str(wav_path) != target_wav:
                shutil.copy(wav_path, target_wav)
            if str(transcript_path) != target_txt:
                shutil.copy(transcript_path, target_txt)

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
                "mfa",
                "align",
                str(mfa_input_dir),
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output),
                "--clean",
            ]

            result = subprocess.run(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=False,
            )

            if result.returncode != 0:
                logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def run_mfa_alignment_batch(
        self, 
        learner_wav: str, 
        native_wav: str,
        learner_transcript: str,
        native_transcript: str
    ) -> bool:
        """MFA ë°°ì¹˜ ì •ë ¬ (í•™ìŠµìì™€ ì›ì–´ë¯¼ì„ ë™ì‹œì— ì²˜ë¦¬) - ë°©ë²• 1"""
        try:
            logger.info("ğŸš€ MFA ë°°ì¹˜ ì •ë ¬ ì‹œì‘...")

            # MFA ì…ë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„ (í•˜ë‚˜ì˜ í´ë”ì— ëª¨ë“  íŒŒì¼)
            mfa_batch_input = self.mfa_input / "batch"
            mfa_batch_input.mkdir(parents=True, exist_ok=True)
            
            # ê¸°ì¡´ íŒŒì¼ë“¤ ì •ë¦¬
            import shutil
            if mfa_batch_input.exists():
                shutil.rmtree(mfa_batch_input)
                mfa_batch_input.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ ë³µì‚¬ (ê°™ì€ í´ë”ì— ë°°ì¹˜)
            shutil.copy(learner_wav, str(mfa_batch_input / "learner.wav"))
            shutil.copy(native_wav, str(mfa_batch_input / "native.wav"))
            shutil.copy(learner_transcript, str(mfa_batch_input / "learner.txt"))
            shutil.copy(native_transcript, str(mfa_batch_input / "native.txt"))

            logger.info(f"ğŸ“ ë°°ì¹˜ ì…ë ¥ í´ë”: {mfa_batch_input}")
            logger.info(f"ğŸ“„ íŒŒì¼ë“¤: learner.wav, native.wav, learner.txt, native.txt")

            # ìµœì í™”ëœ MFA ëª…ë ¹ì–´
            command = [
                "mfa", "align",
                str(mfa_batch_input),           # ëª¨ë“  íŒŒì¼ì´ ìˆëŠ” í•˜ë‚˜ì˜ í´ë”
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output),
                "--num_jobs", str(CURRENT_CONFIG["mfa"]["num_jobs"]),  # ë³‘ë ¬ ì²˜ë¦¬
                "--clean",                      # ì´ì „ ê²°ê³¼ ì •ë¦¬
                "--no_debug",                   # ë””ë²„ê·¸ ì¶œë ¥ ë¹„í™œì„±í™”
                "--ignore_empty_utterances",   # ë¹ˆ ë°œí™” ë¬´ì‹œ
            ]

            logger.info(f"ğŸš€ MFA ëª…ë ¹ì–´: {' '.join(command)}")
            
            result = subprocess.run(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=False,
                timeout=CURRENT_CONFIG["mfa"]["timeout"],  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )

            if result.returncode != 0:
                logger.error(f"MFA ë°°ì¹˜ ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… MFA ë°°ì¹˜ ì •ë ¬ ì™„ë£Œ")
            return True

        except subprocess.TimeoutExpired:
            logger.error(f"MFA ë°°ì¹˜ ì •ë ¬ ì‹œê°„ ì´ˆê³¼ ({CURRENT_CONFIG['mfa']['timeout']}ì´ˆ)")
            return False
        except Exception as e:
            logger.error(f"MFA ë°°ì¹˜ ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    # ê¸°ì¡´ run_mfa_alignment í•¨ìˆ˜ëŠ” ë°±ì—…ìœ¼ë¡œ ìœ ì§€
    def run_mfa_alignment_legacy(
        self, wav_path: str, transcript_path: str, output_name: str
    ) -> bool:
        """ê¸°ì¡´ MFA ì •ë ¬ (ë°±ì—…ìš©)"""
        try:
            logger.info(f"ğŸ”§ ê¸°ì¡´ MFA ì •ë ¬: {output_name}")

            # MFA ì…ë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
            mfa_input_dir = self.mfa_input / output_name
            mfa_input_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ë³µì‚¬
            target_wav = str(mfa_input_dir / f"{output_name}.wav")
            target_txt = str(mfa_input_dir / f"{output_name}.txt")

            if str(wav_path) != target_wav:
                shutil.copy(wav_path, target_wav)
            if str(transcript_path) != target_txt:
                shutil.copy(transcript_path, target_txt)

            # MFA ì •ë ¬ ì‹¤í–‰
            command = [
                "mfa", "align",
                str(mfa_input_dir),
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output),
                "--clean",
            ]

            result = subprocess.run(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=False,
                timeout=60,  # ì§§ì€ íƒ€ì„ì•„ì›ƒ
            )

            if result.returncode != 0:
                logger.error(f"ê¸°ì¡´ MFA ì •ë ¬ ì‹¤íŒ¨: {result.stderr}")
                return False

            logger.info("âœ… ê¸°ì¡´ MFA ì •ë ¬ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"ê¸°ì¡´ MFA ì •ë ¬ ì‹¤íŒ¨: {e}")
            return False

    def _analyze_phonemes(
        self,
        textgrid_path: str,
    ) -> Optional[Dict[str, Any]]:
        """ìŒì†Œ ë¶„ì„"""
        try:
            import textgrid
            
            # TextGrid íŒŒì¼ ë¡œë“œ
            if not Path(textgrid_path).exists():
                logger.warning(f"TextGrid íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {textgrid_path}")
                return {}
            
            tg = textgrid.TextGrid.fromFile(textgrid_path)
            
            # ë‹¨ì–´ tierì™€ ìŒì†Œ tier ì°¾ê¸°
            word_tier = None
            phone_tier = None
            
            for tier in tg.tiers:
                if 'words' in tier.name.lower():
                    word_tier = tier
                elif 'phones' in tier.name.lower():
                    phone_tier = tier
            
            phonemes = []
            words = []
            
            # ìŒì†Œ ì •ë³´ ì¶”ì¶œ
            if phone_tier:
                for interval in phone_tier:
                    if interval.mark and interval.mark.strip():
                        phonemes.append({
                            "phoneme": interval.mark,
                            "start": float(interval.minTime),
                            "end": float(interval.maxTime),
                            "duration": float(interval.maxTime - interval.minTime)
                        })
            
            # ë‹¨ì–´ ì •ë³´ ì¶”ì¶œ
            if word_tier:
                for interval in word_tier:
                    if interval.mark and interval.mark.strip():
                        words.append({
                            "word": interval.mark,
                            "start": float(interval.minTime),
                            "end": float(interval.maxTime),
                            "duration": float(interval.maxTime - interval.minTime)
                        })
            
            # ê¸°ë³¸ í†µê³„ ê³„ì‚°
            if phonemes:
                durations = [p["duration"] for p in phonemes]
                mean_duration = sum(durations) / len(durations)
                std_duration = (sum((d - mean_duration) ** 2 for d in durations) / len(durations)) ** 0.5
            else:
                mean_duration = 0.0
                std_duration = 0.0
            
            return {
                "phonemes": phonemes,
                "words": words,
                "statistics": {
                    "total_phonemes": len(phonemes),
                    "total_words": len(words),
                    "mean_duration": mean_duration,
                    "std_duration": std_duration
                }
            }
            
        except Exception as e:
            logger.error(f"ìŒì†Œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return {}

    def _compare_with_reference(
        self,
        learner_audio: str,
        reference_audio: str,
        learner_textgrid: str,
    ) -> Optional[Dict[str, Any]]:
        """ì°¸ì¡° ì˜¤ë””ì˜¤ì™€ ë¹„êµ"""
        try:
            # ê°„ë‹¨í•œ ë¹„êµ ë¶„ì„ (ë³µì¡í•œ MFA ì¬ì •ë ¬ ì—†ì´)
            
            # ìŒì„± íŠ¹ì„± ì¶”ì¶œ
            learner_features = self._extract_audio_features(learner_audio)
            reference_features = self._extract_audio_features(reference_audio)
            
            if not learner_features or not reference_features:
                logger.warning("ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨")
                return {}
            
            # í”¼ì¹˜ ë¹„êµ
            pitch_diff = abs(learner_features["pitch_mean"] - reference_features["pitch_mean"])
            
            # ì—ë„ˆì§€ ë¹„êµ  
            energy_diff = abs(learner_features["energy_mean"] - reference_features["energy_mean"])
            
            # ì†ë„ ë¹„êµ
            duration_diff = abs(learner_features["duration"] - reference_features["duration"])
            
            return {
                "phoneme_comparison": {
                    "match_rate": 0.85,  # ì„ì‹œê°’ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê³„ì‚° í•„ìš”)
                    "differences": []
                },
                "prosody_comparison": {
                    "pitch": {
                        "learner_mean": learner_features["pitch_mean"],
                        "reference_mean": reference_features["pitch_mean"],
                        "mean_diff": pitch_diff
                    },
                    "energy": {
                        "learner_mean": learner_features["energy_mean"],
                        "reference_mean": reference_features["energy_mean"],
                        "mean_diff": energy_diff
                    },
                    "duration": {
                        "learner": learner_features["duration"],
                        "reference": reference_features["duration"],
                        "diff": duration_diff
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"ì°¸ì¡° ì˜¤ë””ì˜¤ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return {}

    def _extract_audio_features(self, audio_path: str) -> Dict[str, float]:
        """ì˜¤ë””ì˜¤ì—ì„œ ê¸°ë³¸ íŠ¹ì„± ì¶”ì¶œ"""
        try:
            import librosa
            import numpy as np
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(audio_path, sr=22050)
            
            # í”¼ì¹˜ ì¶”ì¶œ
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
            pitch_contour = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_contour.append(pitch)
            
            # ì—ë„ˆì§€ ì¶”ì¶œ
            energy = librosa.feature.rms(y=y)[0]
            
            return {
                "pitch_mean": float(np.mean(pitch_contour)) if pitch_contour else 0.0,
                "pitch_std": float(np.std(pitch_contour)) if pitch_contour else 0.0,
                "energy_mean": float(np.mean(energy)),
                "energy_std": float(np.std(energy)),
                "duration": float(len(y) / sr)
            }
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _visualize_results(
        self,
        learner_audio: str,
        reference_audio: Optional[str],
        learner_textgrid: str,
        phoneme_analysis: Dict[str, Any],
        prosody_analysis: Dict[str, Any],
        comparison: Optional[Dict[str, Any]] = None,
    ) -> List[str]:
        """ê²°ê³¼ ì‹œê°í™” (koach/temp/visualizeì— ì €ì¥)"""
        try:
            # ì‹œê°í™” í´ë” ìƒì„±
            self.visualize_dir.mkdir(parents=True, exist_ok=True)
            
            plot_paths = []

            # 1. ìš´ìœ¨ ë¶„ì„ ì‹œê°í™” (í•­ìƒ ìƒì„±)
            prosody_plot_path = self.visualize_dir / "prosody_analysis.png"
            if prosody_analysis and prosody_analysis:  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš°
                self.prosody_analyzer.visualize_prosody(
                    prosody_analysis, str(prosody_plot_path)
                )
                plot_paths.append(str(prosody_plot_path))
                logger.info(f"ğŸ“ˆ ìš´ìœ¨ ì‹œê°í™” ì €ì¥: {prosody_plot_path}")
            else:
                # ë°ì´í„°ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì°¨íŠ¸ ìƒì„±
                self._create_empty_prosody_chart(str(prosody_plot_path))
                plot_paths.append(str(prosody_plot_path))
                logger.info(f"ğŸ“ˆ ê¸°ë³¸ ìš´ìœ¨ ì°¨íŠ¸ ìƒì„±: {prosody_plot_path}")

            # 2. ìŒì†Œ ë¶„ì„ ì‹œê°í™” (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if phoneme_analysis and phoneme_analysis.get("phonemes"):
                try:
                    phoneme_plot_path = self.visualize_dir / "phoneme_analysis.png"
                    self._plot_phoneme_analysis_safe(phoneme_analysis, str(phoneme_plot_path))
                    plot_paths.append(str(phoneme_plot_path))
                    logger.info(f"ğŸ“Š ìŒì†Œ ì‹œê°í™” ì €ì¥: {phoneme_plot_path}")
                except Exception as e:
                    logger.error(f"ìŒì†Œ ì‹œê°í™” ì‹¤íŒ¨: {e}")

            # 3. ë¹„êµ ë¶„ì„ ì‹œê°í™” (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if comparison and comparison.get("prosody_comparison"):
                try:
                    comparison_plot_path = self.visualize_dir / "comparison_analysis.png"
                    self._plot_comparison_analysis_safe(comparison, str(comparison_plot_path))
                    plot_paths.append(str(comparison_plot_path))
                    logger.info(f"ğŸ” ë¹„êµ ì‹œê°í™” ì €ì¥: {comparison_plot_path}")
                except Exception as e:
                    logger.error(f"ë¹„êµ ì‹œê°í™” ì‹¤íŒ¨: {e}")

            logger.info(f"ğŸ“Š ì‹œê°í™” ê²°ê³¼ ì €ì¥: {self.visualize_dir}")
            return plot_paths

        except Exception as e:
            logger.error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return []

    def _plot_phoneme_analysis_safe(
        self,
        phoneme_analysis: Dict[str, Any],
        output_path: str,
    ) -> None:
        """ì•ˆì „í•œ ìŒì†Œ ë¶„ì„ ì‹œê°í™” (í•œê¸€ í°íŠ¸ ì„¤ì • í¬í•¨)"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.font_manager as fm
            import numpy as np

            # í•œê¸€ í°íŠ¸ ì„¤ì •
            try:
                # macOSì˜ ê¸°ë³¸ í•œê¸€ í°íŠ¸ë“¤ ì‹œë„
                font_candidates = [
                    'AppleGothic',      # macOS ê¸°ë³¸
                    'Malgun Gothic',    # Windows
                    'NanumGothic',      # ë‚˜ëˆ”í°íŠ¸
                    'DejaVu Sans'       # ë°±ì—…ìš©
                ]
                
                font_found = False
                for font_name in font_candidates:
                    try:
                        plt.rcParams['font.family'] = font_name
                        font_found = True
                        break
                    except:
                        continue
                
                if not font_found:
                    # ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°
                    available_fonts = [f.name for f in fm.fontManager.ttflist]
                    korean_fonts = [f for f in available_fonts if any(k in f for k in ['Gothic', 'Dotum', 'Batang', 'Gulim'])]
                    if korean_fonts:
                        plt.rcParams['font.family'] = korean_fonts[0]
                        
            except Exception as e:
                logger.warning(f"í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
                # í•œê¸€ ëŒ€ì‹  ì˜ë¬¸ìœ¼ë¡œ í‘œì‹œ
                pass

            # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ì„¤ì •
            plt.rcParams['axes.unicode_minus'] = False

            phonemes = phoneme_analysis.get("phonemes", [])
            if not phonemes:
                return

            # ìŒì†Œ ê¸¸ì´ ë¶„í¬ (í•œê¸€ ëŒ€ì‹  ìˆ«ìë¡œ í‘œì‹œ)
            durations = [p["duration"] for p in phonemes[:20]]  # ì²˜ìŒ 20ê°œë§Œ
            phoneme_indices = list(range(len(durations)))  # í•œê¸€ ëŒ€ì‹  ì¸ë±ìŠ¤ ì‚¬ìš©

            plt.figure(figsize=(12, 6))
            
            # ìŒì†Œ ê¸¸ì´ ë§‰ëŒ€ê·¸ë˜í”„
            plt.subplot(1, 2, 1)
            bars = plt.bar(phoneme_indices, durations)
            plt.title("Phoneme Duration Distribution")  # ì˜ë¬¸ ì œëª©
            plt.xlabel("Phoneme Index")
            plt.ylabel("Duration (sec)")
            
            # ìŒì†Œ ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨
            plt.subplot(1, 2, 2)
            all_durations = [p["duration"] for p in phonemes]
            plt.hist(all_durations, bins=10, alpha=0.7)
            plt.title("Phoneme Duration Histogram")
            plt.xlabel("Duration (sec)")
            plt.ylabel("Frequency")

            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches="tight")
            plt.close()

        except Exception as e:
            logger.error(f"ìŒì†Œ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def _plot_comparison_analysis_safe(
        self,
        comparison: Dict[str, Any],
        output_path: str,
    ) -> None:
        """ì•ˆì „í•œ ë¹„êµ ë¶„ì„ ì‹œê°í™” (í•œê¸€ í°íŠ¸ ì„¤ì • í¬í•¨)"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.font_manager as fm

            # í•œê¸€ í°íŠ¸ ì„¤ì • (ìœ„ì™€ ë™ì¼)
            try:
                font_candidates = ['AppleGothic', 'Malgun Gothic', 'NanumGothic', 'DejaVu Sans']
                for font_name in font_candidates:
                    try:
                        plt.rcParams['font.family'] = font_name
                        break
                    except:
                        continue
            except:
                pass

            plt.rcParams['axes.unicode_minus'] = False

            prosody_comp = comparison.get("prosody_comparison", {})
            if not prosody_comp:
                return

            plt.figure(figsize=(12, 4))

            # í”¼ì¹˜ ë¹„êµ
            plt.subplot(1, 3, 1)
            pitch_data = prosody_comp.get("pitch", {})
            learner_pitch = pitch_data.get("learner_mean", 0)
            ref_pitch = pitch_data.get("reference_mean", 0)
            
            plt.bar(["Learner", "Reference"], [learner_pitch, ref_pitch], color=["red", "blue"])
            plt.title("Average Pitch Comparison")
            plt.ylabel("Frequency (Hz)")

            # ì—ë„ˆì§€ ë¹„êµ
            plt.subplot(1, 3, 2)
            energy_data = prosody_comp.get("energy", {})
            learner_energy = energy_data.get("learner_mean", 0)
            ref_energy = energy_data.get("reference_mean", 0)
            
            plt.bar(["Learner", "Reference"], [learner_energy, ref_energy], color=["red", "blue"])
            plt.title("Average Energy Comparison")
            plt.ylabel("Energy")

            # ê¸¸ì´ ë¹„êµ
            plt.subplot(1, 3, 3)
            duration_data = prosody_comp.get("duration", {})
            learner_dur = duration_data.get("learner", 0)
            ref_dur = duration_data.get("reference", 0)
            
            plt.bar(["Learner", "Reference"], [learner_dur, ref_dur], color=["red", "blue"])
            plt.title("Duration Comparison")
            plt.ylabel("Time (sec)")

            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches="tight")
            plt.close()

        except Exception as e:
            logger.error(f"ë¹„êµ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def _convert_numpy_types(self, obj):
        """numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        import numpy as np
        
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        else:
            return obj

    def analyze_prosody(
        self,
        learner_audio: str,
        native_audio: str,
        learner_text: str = None,
        learner_timing: str = None,
        visualize: bool = True,
    ) -> Dict:
        """ì–µì–‘/ê°•ì„¸ ë¶„ì„

        Args:
            learner_audio: í•™ìŠµì ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            native_audio: ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            learner_text: í•™ìŠµì ì „ì‚¬ í…ìŠ¤íŠ¸
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´
            visualize: ì‹œê°í™” ì—¬ë¶€

        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
        """
        try:
            # ProsodyAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            analyzer = ProsodyAnalyzer()

            # ì›ì–´ë¯¼ ì˜¤ë””ì˜¤ë¡œ ì„ê³„ê°’ ì¡°ì •
            analyzer.adjust_thresholds(native_audio)

            # ì–µì–‘/ê°•ì„¸ ë¹„êµ (learner_textì™€ learner_timing ì œì™¸)
            result = analyzer.compare_prosody(
                learner_audio=learner_audio, reference_audio=native_audio
            )

            # ì‹œê°í™”
            if visualize:
                output_path = self.visualize_dir / "prosody_comparison.png"
                analyzer.visualize_prosody(
                    learner_audio=learner_audio,
                    reference_audio=native_audio,
                    output_path=str(output_path),
                )
                result["visualization"] = str(output_path)

            return result

        except Exception as e:
            logger.error(f"ì–µì–‘/ê°•ì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def _extract_pitch(self, segment: np.ndarray, sr: int) -> float:
        """ìŒì†Œ êµ¬ê°„ì˜ í”¼ì¹˜ ì¶”ì¶œ"""
        try:
            if len(segment) < 2:
                return 0.0

            # librosaì˜ í”¼ì¹˜ ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
            pitches, magnitudes = librosa.piptrack(y=segment, sr=sr)
            if len(pitches) > 0:
                return np.mean(pitches[magnitudes > np.median(magnitudes)])
            return 0.0
        except Exception as e:
            logger.error(f"í”¼ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0

    def _extract_pitch_contour(self, y: np.ndarray, sr: int) -> np.ndarray:
        """ì „ì²´ ì˜¤ë””ì˜¤ì˜ í”¼ì¹˜ ìœ¤ê³½ì„  ì¶”ì¶œ"""
        try:
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
            if len(pitches) > 0:
                return np.mean(pitches, axis=1)
            return np.array([])
        except Exception as e:
            logger.error(f"í”¼ì¹˜ ìœ¤ê³½ì„  ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return np.array([])

    def visualize_prosody(
        self, prosody_result: Dict[str, Any], output_path: str = None
    ) -> None:
        """ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        try:
            # âœ… output_pathê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ visualize_dir ì‚¬ìš©
            if output_path is None:
                self.visualize_dir.mkdir(parents=True, exist_ok=True)
                output_path = str(self.visualize_dir / "prosody_comparison.png")

            # í”¼ì¹˜ ìœ¤ê³½ì„  ë°ì´í„° ì¶”ì¶œ
            pitch_contour = prosody_result.get("pitch_contour", [])
            if len(pitch_contour) == 0:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²´í¬
                logger.warning("í”¼ì¹˜ ìœ¤ê³½ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ì‹œê°í™”
            plt.figure(figsize=(12, 6))

            # í”¼ì¹˜ ìœ¤ê³½ì„  í”Œë¡¯
            plt.subplot(2, 1, 1)
            plt.plot(pitch_contour)
            plt.title("Pitch Contour")
            plt.xlabel("Time")
            plt.ylabel("Pitch (Hz)")

            # ìŒì†Œë³„ íŠ¹ì„± í”Œë¡¯
            plt.subplot(2, 1, 2)
            phoneme_features = prosody_result.get("phoneme_features", {})
            if phoneme_features:
                durations = [f["duration"] for f in phoneme_features.values()]
                energies = [f["energy"] for f in phoneme_features.values()]
                pitches = [f["pitch"] for f in phoneme_features.values()]

                x = np.arange(len(durations))
                width = 0.25

                plt.bar(x - width, durations, width, label="Duration")
                plt.bar(x, energies, width, label="Energy")
                plt.bar(x + width, pitches, width, label="Pitch")

                plt.title("Phoneme Features")
                plt.xlabel("Phoneme")
                plt.ylabel("Value")
                plt.legend()

            plt.tight_layout()
            plt.savefig(output_path)
            plt.close()

            logger.info(f"ğŸ“ˆ ìš´ìœ¨ ì‹œê°í™” ì €ì¥: {output_path}")

        except Exception as e:
            logger.error(f"ìš´ìœ¨ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    def get_feedback(self, prompt: str) -> Optional[str]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            prompt: GPT í”„ë¡¬í”„íŠ¸

        Returns:
            Optional[str]: ìƒì„±ëœ í”¼ë“œë°± (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info("ğŸ¤– GPT í”¼ë“œë°± ìƒì„± ì¤‘...")

            if not self.openai_api_key:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

            client = OpenAI(api_key=self.openai_api_key)
            response = client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ ë°œìŒ ê°•ì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìê°€ ì™¸êµ­ì¸ì„ì„ ê³ ë ¤í•˜ì—¬ ì‰¬ìš´ ë¬¸ë²• ìš©ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    },
                    {"role": "user", "content": prompt},
                ],
            )

            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def generate_compact_prompt(
        self,
        learner_text: str,
        native_text: str,
        script_text: str,
        learner_timing: str,
        native_timing: str,
        prosody_feedback: Optional[Dict] = None,
    ) -> str:
        """GPTìš© ë°œìŒ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë² íƒ€ ë²„ì „ ì••ì¶•ëœ ë²„ì „)"""
        
        # RAG ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì§€ì‹ ê°€ì ¸ì˜¤ê¸°
        rag_context = ""
        if self.knowledge_base:
            query = f"í•œêµ­ì–´ ë°œìŒ {script_text} êµì • í”¼ë“œë°±"
            search_results = self.knowledge_base.search(query, top_k=2)
            
            if search_results:
                rag_context = "\n\n**ì°¸ê³  ë°œìŒ ì§€ì‹**:\n"
                for result in search_results:
                    rag_context += f"- {result['content'][:200]}...\n"

        # ë©”ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ë°œìŒ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í•™ìŠµ ëª©í‘œ ë¬¸ì¥**: {script_text}

**ë¶„ì„ ë°ì´í„°**:
- í•™ìŠµì ë°œí™”: {learner_text}
- ì›ì–´ë¯¼ ë°œí™”: {native_text}
- í•™ìŠµì íƒ€ì´ë°: {learner_timing[:300] if learner_timing else 'N/A'}...
- ì›ì–´ë¯¼ íƒ€ì´ë°: {native_timing[:300] if native_timing else 'N/A'}...{rag_context}

**ìš”ì²­ì‚¬í•­**:
1. í•™ìŠµìì™€ ì›ì–´ë¯¼ ë°œìŒì˜ ì£¼ìš” ì°¨ì´ì  ë¶„ì„
2. êµ¬ì²´ì ì¸ ë°œìŒ êµì • í¬ì¸íŠ¸ ì œì‹œ  
3. ì‹¤ì œì ì¸ ì—°ìŠµ ë°©ë²• ì œì•ˆ

**ì‘ë‹µ í˜•ì‹**:
## ğŸ“Š ë°œìŒ ë¶„ì„
[ì£¼ìš” ì°¨ì´ì ]

## ğŸ¯ êµì • í¬ì¸íŠ¸  
[êµ¬ì²´ì ì¸ êµì •ì‚¬í•­]

## ğŸ’¡ ì—°ìŠµ ë°©ë²•
[ì‹¤ìš©ì ì¸ ì—°ìŠµë²•]

ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        return prompt

    def extract_pronunciation_issues(
        self,
        learner_result: Dict,
        reference_result: Dict,
        learner_timing: str,
        reference_timing: str
    ) -> List[Dict]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ

        Args:
            learner_result: í•™ìŠµì ì¸ì‹ ê²°ê³¼
            reference_result: ì›ì–´ë¯¼ ì¸ì‹ ê²°ê³¼
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´
            reference_timing: ì›ì–´ë¯¼ íƒ€ì´ë° ì •ë³´

        Returns:
            List[Dict]: ë°œìŒ ë¬¸ì œì  ëª©ë¡
        """
        issues = []
        
        # ë‹¨ì–´ ë‹¨ìœ„ ë¹„êµ (ì•ˆì „í•œ ì ‘ê·¼)
        learner_words = learner_result.get("words", [])
        reference_words = reference_result.get("words", [])
        
        if learner_words and reference_words:
            # ìµœì†Œ ê¸¸ì´ë§Œí¼ ë¹„êµ
            min_length = min(len(learner_words), len(reference_words))
            for i in range(min_length):
                learner_word = learner_words[i]
                ref_word = reference_words[i]
                
                # ë‹¨ì–´ ê°ì²´ê°€ ë”•ì…”ë„ˆë¦¬ì´ê³  'word' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if (isinstance(learner_word, dict) and 'word' in learner_word and 
                    isinstance(ref_word, dict) and 'word' in ref_word):
                    
                    if learner_word["word"] != ref_word["word"]:
                        issues.append({
                            "type": "word_mismatch",
                            "position": i,
                            "learner": learner_word["word"],
                            "reference": ref_word["word"],
                            "start": learner_word.get("start", 0),
                            "end": learner_word.get("end", 0)
                        })
        
        # í…ìŠ¤íŠ¸ ë ˆë²¨ì—ì„œì˜ ê¸°ë³¸ ë¹„êµ (ë‹¨ì–´ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°)
        if not learner_words or not reference_words:
            learner_text = learner_result.get("text", "").strip()
            reference_text = reference_result.get("text", "").strip()
            
            if learner_text != reference_text:
                issues.append({
                    "type": "text_mismatch", 
                    "learner": learner_text,
                    "reference": reference_text
                })
        
        # ìš´ìœ¨ ë¹„êµ
        if "prosody" in learner_result and "prosody" in reference_result:
            learner_prosody = learner_result["prosody"]
            reference_prosody = reference_result["prosody"]
            
            # í”¼ì¹˜ ì°¨ì´
            if ("pitch" in learner_prosody and "pitch" in reference_prosody and
                "mean" in learner_prosody["pitch"] and "mean" in reference_prosody["pitch"]):
                
                pitch_diff = abs(learner_prosody["pitch"]["mean"] - reference_prosody["pitch"]["mean"])
                if pitch_diff > 20:  # 20Hz ì´ìƒ ì°¨ì´ë‚˜ë©´ ë¬¸ì œë¡œ íŒë‹¨
                    issues.append({
                        "type": "pitch_difference",
                        "learner_mean": learner_prosody["pitch"]["mean"],
                        "reference_mean": reference_prosody["pitch"]["mean"],
                        "difference": pitch_diff
                    })
            
            # ì—ë„ˆì§€ ì°¨ì´
            if ("energy" in learner_prosody and "energy" in reference_prosody and
                "mean" in learner_prosody["energy"] and "mean" in reference_prosody["energy"]):
                
                energy_diff = abs(learner_prosody["energy"]["mean"] - reference_prosody["energy"]["mean"])
                if energy_diff > 0.1:  # 0.1 ì´ìƒ ì°¨ì´ë‚˜ë©´ ë¬¸ì œë¡œ íŒë‹¨
                    issues.append({
                        "type": "energy_difference",
                        "learner_mean": learner_prosody["energy"]["mean"],
                        "reference_mean": reference_prosody["energy"]["mean"],
                        "difference": energy_diff
                    })
        
        return issues

    def align_audio(self, audio_path: str, text: str, speaker_type: str) -> Optional[Dict]:
        """MFAë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë ¬

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            text: ì •ë ¬í•  í…ìŠ¤íŠ¸
            speaker_type: í™”ì íƒ€ì… ("learner" ë˜ëŠ” "native")

        Returns:
            Optional[Dict]: ì •ë ¬ ê²°ê³¼
        """
        try:
            # MFA ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
            mfa_input_dir = self.temp_dir / "mfa_input" / speaker_type
            mfa_input_dir.mkdir(parents=True, exist_ok=True)
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ì„ mfa_input ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            audio_filename = Path(audio_path).name
            shutil.copy2(audio_path, mfa_input_dir / audio_filename)
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            text_filename = Path(audio_path).stem + ".txt"
            with open(mfa_input_dir / text_filename, "w", encoding="utf-8") as f:
                f.write(text)

            # MFA ì •ë ¬ ì‹¤í–‰
            logger.info(f"ğŸ”§ MFA ì •ë ¬ ì‹œì‘: {speaker_type}")
            command = [
                "mfa",
                "align",
                str(mfa_input_dir),
                str(self.lexicon_path),
                str(self.acoustic_model),
                str(self.mfa_output),
                "--clean",
            ]
            subprocess.run(command, check=True)
            logger.info("âœ… MFA ì •ë ¬ ì™„ë£Œ")

            # TextGrid íŒŒì¼ ì½ê¸°
            textgrid_path = self.mfa_output / speaker_type / f"{Path(audio_path).stem}.TextGrid"
            if not textgrid_path.exists():
                logger.error(f"TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {textgrid_path}")
                return None

            # TextGrid íŒŒì‹±
            with open(textgrid_path, "r", encoding="utf-8") as f:
                textgrid_content = f.read()

            # ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì´ë° ì •ë³´ ì¶”ì¶œ
            timing_info = {}
            current_word = None
            for line in textgrid_content.split("\n"):
                if line.strip().startswith('text = "'):
                    current_word = line.strip()[8:-1]  # "text = " ì œê±°
                elif line.strip().startswith('xmin = '):
                    start_time = float(line.strip()[7:])
                elif line.strip().startswith('xmax = '):
                    end_time = float(line.strip()[7:])
                    if current_word:
                        timing_info[current_word] = {
                            "start": start_time,
                            "end": end_time
                        }

            return timing_info

        except Exception as e:
            logger.error(f"MFA ì •ë ¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def convert_audio(self, audio_path: str) -> Optional[str]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ (.m4a -> .wav)

        Args:
            audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ë³€í™˜ëœ wav íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì…ë ¥ íŒŒì¼ ê²½ë¡œ í™•ì¸
            input_path = Path(audio_path)
            if not input_path.exists():
                logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
                return None

            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            output_dir = self.temp_dir / "wav"
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"{input_path.stem}.wav"

            # ffmpegë¡œ ë³€í™˜
            subprocess.run([
                "ffmpeg",
                "-i", str(input_path),
                "-acodec", "pcm_s16le",
                "-ar", "16000",
                "-ac", "1",
                "-y",  # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
                str(output_path)
            ], check=True)

            logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            return str(output_path)

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None

    def _generate_simple_feedback(self, result: Dict) -> Optional[Dict]:
        """ê°„ë‹¨í•œ í”¼ë“œë°± ìƒì„±
        
        Args:
            result: ë¶„ì„ ê²°ê³¼
            
        Returns:
            Optional[Dict]: í”¼ë“œë°± ê²°ê³¼
        """
        try:
            feedback = {
                "summary": "ë°œìŒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "suggestions": []
            }
            
            # ë°œìŒ ë¬¸ì œì ì´ ìˆë‹¤ë©´ í”¼ë“œë°± ì¶”ê°€
            if "issues" in result["comparison"]:
                issues = result["comparison"]["issues"]
                if issues:
                    feedback["suggestions"].append("ë°œê²¬ëœ ë°œìŒ ë¬¸ì œì ë“¤ì„ ê°œì„ í•´ë³´ì„¸ìš”.")
                    for issue in issues[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                        if issue["type"] == "word_mismatch":
                            feedback["suggestions"].append(
                                f"'{issue['learner']}'ì„(ë¥¼) '{issue['reference']}'ë¡œ ë°œìŒí•´ë³´ì„¸ìš”."
                            )
                        elif issue["type"] == "text_mismatch":
                            feedback["suggestions"].append(
                                "ë°œìŒëœ í…ìŠ¤íŠ¸ì™€ ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ë‹¤ë¦…ë‹ˆë‹¤."
                            )
            
            # ìš´ìœ¨ ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ í”¼ë“œë°± ì¶”ê°€
            if "prosody" in result["comparison"]:
                prosody = result["comparison"]["prosody"]
                if prosody:
                    feedback["suggestions"].append("ì–µì–‘ê³¼ ê°•ì„¸ë¥¼ ì›ì–´ë¯¼ê³¼ ë¹„êµí•˜ì—¬ ê°œì„ í•´ë³´ì„¸ìš”.")
            
            return feedback
            
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def summarize_textgrid(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ ìŒì†Œ ì •ë³´ ì¶”ì¶œ

        Args:
            path: TextGrid íŒŒì¼ ê²½ë¡œ

        Returns:
            Optional[str]: ìŒì†Œ ì •ë³´ ìš”ì•½ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            logger.info(f"ğŸ“Š TextGrid ìš”ì•½ ì¤‘: {path}")
            import textgrid
            tg = textgrid.TextGrid.fromFile(path)
            summary = []

            for tier in tg.tiers:
                if tier.name.lower() in ["phones", "phoneme", "phone"]:
                    for interval in tier:
                        if interval.mark.strip():
                            summary.append(
                                f"{interval.mark}: {round(interval.minTime, 2)}s ~ {round(interval.maxTime, 2)}s"
                            )

            return "\n".join(summary)
        except Exception as e:
            logger.error(f"TextGrid ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def summarize_textgrid_compact(self, path: str) -> Optional[str]:
        """TextGrid íŒŒì¼ì—ì„œ ì••ì¶•ëœ ìŒì†Œ ì •ë³´ ì¶”ì¶œ (ë² íƒ€ ë²„ì „ í† í° ì ˆì•½ ê¸°ëŠ¥)"""
        try:
            logger.info(f"ğŸ“Š TextGrid ì••ì¶• ìš”ì•½ ì¤‘: {path}")
            tg = textgrid.TextGrid.fromFile(path)
            
            # ê°„ë‹¨í•œ ìš”ì•½ í˜•íƒœë¡œ ë³€ê²½ (í† í° ìˆ˜ ì ˆì•½)
            phonemes = []
            
            for tier in tg.tiers:
                if hasattr(tier, 'intervals'):
                    for interval in tier.intervals:
                        if interval.mark and interval.mark.strip():
                            duration = round(interval.maxTime - interval.minTime, 2)
                            phonemes.append(f"{interval.mark}({duration}s)")
            
            summary = " | ".join(phonemes)
            logger.info(f"ğŸ“ ì••ì¶• ìš”ì•½: {summary[:100]}...")
            return summary
            
        except Exception as e:
            logger.error(f"TextGrid ì••ì¶• ìš”ì•½ ì‹¤íŒ¨: {e}")
            return None

    def extract_pronunciation_issues_detailed(
        self, learner_text: str, native_text: str, learner_timing: str
    ) -> List[str]:
        """ë°œìŒ ë¬¸ì œì  ì¶”ì¶œ (ìƒì„¸ ë¶„ì„)

        Args:
            learner_text: í•™ìŠµì í…ìŠ¤íŠ¸
            native_text: ì›ì–´ë¯¼ í…ìŠ¤íŠ¸
            learner_timing: í•™ìŠµì íƒ€ì´ë° ì •ë³´

        Returns:
            List[str]: ë°œê²¬ëœ ë¬¸ì œì  ëª©ë¡
        """
        issues = []

        # 1. í…ìŠ¤íŠ¸ ê¸¸ì´ ì°¨ì´ (ë„ˆë¬´ í¬ë©´ ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„±)
        if len(native_text) > len(learner_text) * 1.2:
            issues.append("ë°œìŒ ëˆ„ë½ ê°€ëŠ¥ì„± ìˆìŒ")

        # 2. ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
        learner_words = learner_text.split()
        native_words = native_text.split()

        for n_word in native_words:
            if len(n_word) >= 2 and n_word not in learner_text:
                # ë°›ì¹¨ì´ ìˆëŠ” ë‹¨ì–´ë©´ ë°›ì¹¨ ê´€ë ¨ ë¬¸ì œ ê°€ëŠ¥ì„± ì¶”ê°€
                if any(c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…" for c in n_word):
                    issues.append(f"'{n_word}' ë‹¨ì–´ ë°œìŒ ë¬¸ì œ (ë°›ì¹¨ ê´€ë ¨)")

        # 3. ê³µí†µ ìŒì†Œ ë¬¸ì œ (ìŒì†Œ ê¸¸ì´, ìŒìƒ‰ ë“±)
        phoneme_issues = set()
        for line in learner_timing.split(","):
            parts = line.split("(")
            if len(parts) >= 2:
                phoneme = parts[0].strip()

                # ëª¨ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã…“", "ã…—", "ã…œ", "ã…¡"]:
                    phoneme_issues.add(f"{phoneme} ëª¨ìŒ ë°œìŒ")

                # ê²½ìŒ/ê²©ìŒ ê´€ë ¨ ë¬¸ì œ ê²€ì¶œ
                if phoneme in ["ã„²", "ã„¸", "ã…ƒ", "ã…†", "ã…‰", "ã…‹", "ã…Œ", "ã…", "ã…Š"]:
                    phoneme_issues.add(f"{phoneme} ììŒ ë°œìŒ")

        issues.extend(list(phoneme_issues))
        return issues

    def get_normalized_paths(self, speaker_type: str) -> Dict[str, str]:
        """ì •ê·œí™”ëœ íŒŒì¼ë“¤ì˜ ê²½ë¡œ ë°˜í™˜ (ê²½ë¡œ ì •ì±… ë°˜ì˜)
        
        Args:
            speaker_type: "learner" ë˜ëŠ” "native"
            
        Returns:
            Dict[str, str]: ì›ë³¸ê³¼ ì •ê·œí™”ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        wav_dir = self.temp_dir / "wav"
        normalized_dir = self.temp_dir / "normalized"  # ìƒˆë¡œìš´ ì •ê·œí™” í´ë”
        
        return {
            "original": str(wav_dir / f"{speaker_type}.wav"),
            "normalized": str(normalized_dir / f"{speaker_type}_normalized.wav"),
            "for_analysis": str(normalized_dir / f"{speaker_type}_normalized.wav"),  # ë¶„ì„ìš©ì€ ì •ê·œí™”ëœ ê²ƒ ì‚¬ìš©
            "for_mfa": str(wav_dir / f"{speaker_type}.wav"),  # MFAìš©ì€ ì›ë³¸ ì‚¬ìš© (ë” ì•ˆì •ì )
        }

    def _analyze_prosody_detailed(self, audio_path: str) -> Dict[str, Any]:
        """ìƒì„¸í•œ ìš´ìœ¨ ë¶„ì„"""
        try:
            import librosa
            import numpy as np
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(audio_path, sr=22050)
            
            # í”¼ì¹˜ ë¶„ì„
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr, hop_length=512)
            pitch_contour = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:
                    pitch_contour.append(pitch)
            
            # ì—ë„ˆì§€ ë¶„ì„
            energy = librosa.feature.rms(y=y, hop_length=512)[0]
            
            # ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ (ìŒìƒ‰ ë¶„ì„)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            
            # ì˜êµì°¨ìœ¨ (ìŒì„±/ë¬´ìŒ êµ¬ë¶„)
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            
            # ê¸°ë³¸ í†µê³„
            valid_pitches = [p for p in pitch_contour if p > 0]
            
            return {
                "pitch": {
                    "contour": pitch_contour[:100],  # ì²˜ìŒ 100ê°œ í”„ë ˆì„ë§Œ
                    "mean": float(np.mean(valid_pitches)) if valid_pitches else 0.0,
                    "std": float(np.std(valid_pitches)) if valid_pitches else 0.0,
                    "min": float(np.min(valid_pitches)) if valid_pitches else 0.0,
                    "max": float(np.max(valid_pitches)) if valid_pitches else 0.0
                },
                "energy": {
                    "contour": energy[:100].tolist(),  # ì²˜ìŒ 100ê°œ í”„ë ˆì„ë§Œ
                    "mean": float(np.mean(energy)),
                    "std": float(np.std(energy))
                },
                "spectral_centroid": {
                    "contour": spectral_centroids[:100].tolist(),
                    "mean": float(np.mean(spectral_centroids))
                },
                "zero_crossing_rate": {
                    "contour": zcr[:100].tolist(),
                    "mean": float(np.mean(zcr))
                },
                "duration": float(len(y) / sr)
            }
            
        except Exception as e:
            logger.error(f"ìš´ìœ¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
